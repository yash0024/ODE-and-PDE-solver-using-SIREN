{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7ssgRISRczf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim, cuda\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from timeit import default_timer as timer\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the dataset; consists only of times in an interval [a, b]\n",
        "\n",
        "class Data(Dataset):\n",
        "  def __init__(self, t):\n",
        "    self.t = torch.from_numpy(t.astype(np.float32))\n",
        "    self.length = np.shape(t)[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.t[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length"
      ],
      "metadata": {
        "id": "kMWAIfh8RfJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SineLayer(nn.Module):\n",
        "    # This class definition is borrowed from the paper Implicit Neural Representations with Periodic Activation Functions by\n",
        "    # Sitzmann, Vincent et al. (2020)\n",
        "\n",
        "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the\n",
        "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a\n",
        "    # hyperparameter.\n",
        "\n",
        "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of\n",
        "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 is_first=False, omega_0=30, activ=torch.sin):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "\n",
        "        self.init_weights()\n",
        "        self.activ = activ\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            self.linear.bias.uniform_(-3.14 ,3.14)\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.activ(self.omega_0 * self.linear(input))"
      ],
      "metadata": {
        "id": "EMciIDT5YYa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # This class definition is a modification from the one provided in the paper Implicit Neural Representations with Periodic Activation Functions by\n",
        "    # Sitzmann, Vincent et al. (2020)\n",
        "\n",
        "class Siren(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n",
        "                 first_omega_0=30, hidden_omega_0=2., activ=torch.sin):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = []\n",
        "        self.net.append(SineLayer(in_features, hidden_features,\n",
        "                                  is_first=True, omega_0=first_omega_0, activ=activ))\n",
        "\n",
        "        for i in range(hidden_layers):\n",
        "            self.net.append(SineLayer(hidden_features, hidden_features,\n",
        "                                      is_first=False, omega_0=hidden_omega_0, activ=activ))\n",
        "\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Linear(hidden_features, out_features)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0,\n",
        "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
        "\n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(SineLayer(hidden_features, out_features,\n",
        "                                      is_first=False, omega_0=hidden_omega_0, activ=activ))\n",
        "\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "        self.params = dict(self.net.named_parameters())\n",
        "\n",
        "    def compute_output(self, inputs):\n",
        "      outputs = torch.func.functional_call(self.net, self.params, inputs)\n",
        "      return outputs, outputs\n",
        "\n",
        "# gradients is the derivative of the output of the network w.r.t. input t\n",
        "    def compute_grad(self, inputs):\n",
        "      gradients, values = torch.func.jacrev(self.compute_output, has_aux=True)(inputs)\n",
        "      gradients = torch.squeeze(gradients, -1)\n",
        "      return gradients, values\n",
        "\n",
        "# gradients is the derivative of the output of the network w.r.t. input t. s_gradients is the\n",
        "# double derivative of the output of the network w.r.t. input t\n",
        "    def compute_jac(self, inputs):\n",
        "      s_gradients, values = torch.func.jacrev(self.compute_grad, has_aux=True)(inputs)\n",
        "      gradients, values = self.compute_grad(inputs)\n",
        "      s_gradients = torch.squeeze(s_gradients, -1)\n",
        "      return s_gradients, gradients, values\n",
        "\n",
        "    def forward(self, t):\n",
        "        s_gradients, gradients, outputs = torch.vmap(self.compute_jac, in_dims=(0))(t)\n",
        "        return t, outputs, gradients, s_gradients"
      ],
      "metadata": {
        "id": "D48ka_pASwh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The RHS of our ODE (in the ODEs we considered, this is x'(t)=f(x(t),t) or x''(t)=f(x(t),t));\n",
        "# function definition can be modified to also take higher-order derivative as input as well\n",
        "def func(x, t):\n",
        "  y = -x\n",
        "  return y"
      ],
      "metadata": {
        "id": "3I8MMIk8Goe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the true solution to the ODE\n",
        "def solution_to_ODE(t):\n",
        "  t = np.array(t)\n",
        "  # -np.cos(t) + 2 + (np.cos(1) - 2) / np.sin(1) * np.sin(t)\n",
        "  return np.cos(t) - np.cos(1) / np.sin(1) * np.sin(t)"
      ],
      "metadata": {
        "id": "90wmWq6cHRTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 45\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUhe7QOqgtnb",
        "outputId": "41bfb87b-1296-40fb-af50-518673b87db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1d94bc8270>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validation sets\n",
        "\n",
        "t = np.arange(-2, 2, 0.001)\n",
        "\n",
        "dataset = Data(t.reshape(-1, 1))\n",
        "\n",
        "val_pct = 0.1\n",
        "val_size = int(len(t) * val_pct)\n",
        "train_size = len(t) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "print(len(train_ds), len(val_ds))\n",
        "\n",
        "batch_size = 200\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_ds, batch_size = batch_size, shuffle=True),\n",
        "    'val': DataLoader(val_ds, batch_size = batch_size, shuffle=True),\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQFjfRavfzhN",
        "outputId": "a7484eb1-a9ee-45b0-f164-e5ca3034ea73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3600 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Times to plot the graph at. Note this is equal to the t above\n",
        "\n",
        "t = torch.arange(-2, 2, 0.001)"
      ],
      "metadata": {
        "id": "bO4WzVep98vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "print(f'Train on gpu: {train_on_gpu}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXqWyD53i46o",
        "outputId": "8dc590d2-f59e-4a5a-e405-f7728d6eb40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on gpu: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "def train(model, criteria, optimizer, train_loader, valid_loader, n_epochs):\n",
        "\n",
        "  overall_start = timer()\n",
        "  model.epochs = 0\n",
        "  losses = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      train_loss = valid_loss = 0\n",
        "      start = timer()\n",
        "      for i, data in enumerate(train_loader):\n",
        "        if train_on_gpu:\n",
        "          data = data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criteria(output)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track train loss by multiplying average loss by number of examples in batch\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "\n",
        "        print(\n",
        "              f'Epoch: {epoch}\\t{100 * (i + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
        "              end='\\r')\n",
        "      else:\n",
        "        model.epochs += 1\n",
        "        with torch.no_grad():\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "            for data in valid_loader:\n",
        "              # Tensors to gpu\n",
        "              if train_on_gpu:\n",
        "                  data = data.cuda()\n",
        "\n",
        "              # Forward pass\n",
        "              output = model(data)\n",
        "\n",
        "              # Validation loss\n",
        "              loss = criteria(output)\n",
        "              # Multiply average loss times the number of examples in batch\n",
        "              valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "            losses.append(valid_loss)\n",
        "\n",
        "            # Print training and validation results\n",
        "            print(\n",
        "                f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss} \\tValidation Loss: {valid_loss}'\n",
        "            )\n",
        "  # Attach the optimizer\n",
        "  model.optimizer = optimizer\n",
        "  # Record overall time and print out stats\n",
        "  total_time = timer() - overall_start\n",
        "\n",
        "  print(\n",
        "    f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
        ")\n",
        "  return model, losses"
      ],
      "metadata": {
        "id": "ITwDVjoIjD1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the loss function: x(t), x'(t) and x''(t) are calculated in terms of N(t) and its higher-order derivatives\n",
        "def criteria(out):\n",
        "  loss = nn.functional.mse_loss\n",
        "  return loss(2*out[1] + (4*out[0]-2)*out[2]+(out[0]**2-out[0])*out[3], func(1-out[0] + out[0]*(out[0]-1)*out[1], out[0]))\n"
      ],
      "metadata": {
        "id": "rH0Q_w35obwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function returns the trial solution x(t) of the ODE\n",
        "def evaluate(model, test_ds):\n",
        "  test_ds = test_ds.cuda()\n",
        "  out = model(test_ds)\n",
        "  # test_ds.detach().cpu().numpy(), (1 + output[0].view(1, -1) * output[1][:, 0]).detach().cpu().numpy()\n",
        "  return out[0].detach().cpu().numpy(), (1-out[0] + out[0]*(out[0]-1)*out[1]).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "ZgQEBfbPrcBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the solution to the ODE\n",
        "def plot_outputs(times, model_outputs, true_values):\n",
        "  plt.scatter(times, model_outputs, label = 'model', s = 2)\n",
        "  plt.scatter(times, true_values, label = 'true', s = 2)\n",
        "  plt.xlabel('t')\n",
        "  plt.ylabel('Function at time t')\n",
        "  plt.title('Comparing learnt function with its true value')\n",
        "  plt.legend(loc=\"upper left\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "_NBCyrQ5t160"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing and training the SIREN model with sine activations\n",
        "model = Siren(in_features=1, out_features=1, hidden_features=10,\n",
        "                  hidden_layers=10, outermost_linear=True, first_omega_0=1, hidden_omega_0=1)\n",
        "if train_on_gpu:\n",
        "    model = model.to('cuda')\n",
        "\n",
        "optimizer = torch.optim.RAdam(model.parameters())\n",
        "\n",
        "model, losses = train(model, criteria, optimizer, dataloaders['train'], dataloaders['val'], 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTfPnf8zvKw5",
        "outputId": "e0ff886e-ea29-479e-9f90-71de824f2777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 0 \tTraining Loss: 5.504208664099376 \tValidation Loss: 1.3884296417236328\n",
            "\n",
            "Epoch: 1 \tTraining Loss: 1.2681674659252167 \tValidation Loss: 1.1274652481079102\n",
            "Epoch: 2\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 2 \tTraining Loss: 0.9832680424054464 \tValidation Loss: 0.8714302480220795\n",
            "Epoch: 3\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 3 \tTraining Loss: 0.761901792552736 \tValidation Loss: 0.7037067711353302\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 0.6293765488598082 \tValidation Loss: 0.5982451140880585\n",
            "Epoch: 5\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 5 \tTraining Loss: 0.5418990204731623 \tValidation Loss: 0.5224625468254089\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 0.47305895222557914 \tValidation Loss: 0.45645642280578613\n",
            "Epoch: 7\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 7 \tTraining Loss: 0.41014771660168964 \tValidation Loss: 0.39162664115428925\n",
            "Epoch: 8\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 8 \tTraining Loss: 0.3490974936220381 \tValidation Loss: 0.32920005917549133\n",
            "Epoch: 9\t100.00% complete. 0.68 seconds elapsed in epoch.\n",
            "Epoch: 9 \tTraining Loss: 0.29005493803156746 \tValidation Loss: 0.26931994408369064\n",
            "Epoch: 10\t100.00% complete. 0.74 seconds elapsed in epoch.\n",
            "Epoch: 10 \tTraining Loss: 0.2342834323644638 \tValidation Loss: 0.21365784108638763\n",
            "Epoch: 11\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 11 \tTraining Loss: 0.18423798266384336 \tValidation Loss: 0.1642175167798996\n",
            "Epoch: 12\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 12 \tTraining Loss: 0.1409998262921969 \tValidation Loss: 0.12503061071038246\n",
            "Epoch: 13\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 13 \tTraining Loss: 0.10752495005726814 \tValidation Loss: 0.09422238916158676\n",
            "Epoch: 14\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 14 \tTraining Loss: 0.08172373846173286 \tValidation Loss: 0.07274070382118225\n",
            "Epoch: 15\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 15 \tTraining Loss: 0.06386323252485858 \tValidation Loss: 0.057321805506944656\n",
            "\n",
            "Epoch: 16 \tTraining Loss: 0.050955182355311185 \tValidation Loss: 0.046594999730587006\n",
            "Epoch: 17\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 17 \tTraining Loss: 0.041847798973321915 \tValidation Loss: 0.03886750899255276\n",
            "\n",
            "Epoch: 18 \tTraining Loss: 0.03523033381336265 \tValidation Loss: 0.033214226365089417\n",
            "Epoch: 19\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 19 \tTraining Loss: 0.03029268855849902 \tValidation Loss: 0.028823996894061565\n",
            "\n",
            "Epoch: 20 \tTraining Loss: 0.026461151325040393 \tValidation Loss: 0.025424327701330185\n",
            "Epoch: 21\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 21 \tTraining Loss: 0.02343549600078 \tValidation Loss: 0.022756156511604786\n",
            "\n",
            "Epoch: 22 \tTraining Loss: 0.02100823964509699 \tValidation Loss: 0.020510200411081314\n",
            "Epoch: 23\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 23 \tTraining Loss: 0.01896342459238238 \tValidation Loss: 0.0186461228877306\n",
            "\n",
            "Epoch: 24 \tTraining Loss: 0.017237244070404105 \tValidation Loss: 0.016998025588691235\n",
            "Epoch: 25\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 25 \tTraining Loss: 0.015724596050050523 \tValidation Loss: 0.01556441094726324\n",
            "\n",
            "Epoch: 26 \tTraining Loss: 0.01437803285403384 \tValidation Loss: 0.014276147820055485\n",
            "Epoch: 27\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 27 \tTraining Loss: 0.01317134385721551 \tValidation Loss: 0.013104090467095375\n",
            "Epoch: 28\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 28 \tTraining Loss: 0.012064891091237465 \tValidation Loss: 0.012051081284880638\n",
            "Epoch: 29\t100.00% complete. 0.71 seconds elapsed in epoch.\n",
            "Epoch: 29 \tTraining Loss: 0.011073755100369453 \tValidation Loss: 0.011062786914408207\n",
            "Epoch: 30\t100.00% complete. 0.77 seconds elapsed in epoch.\n",
            "Epoch: 30 \tTraining Loss: 0.010149165574047301 \tValidation Loss: 0.010194370523095131\n",
            "\n",
            "Epoch: 31 \tTraining Loss: 0.009331263032638364 \tValidation Loss: 0.009356296621263027\n",
            "Epoch: 32\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 32 \tTraining Loss: 0.008552357269864943 \tValidation Loss: 0.008604652248322964\n",
            "Epoch: 33\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 33 \tTraining Loss: 0.007849072804674506 \tValidation Loss: 0.00792281050235033\n",
            "Epoch: 34\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 34 \tTraining Loss: 0.007211986127206021 \tValidation Loss: 0.007295755436643958\n",
            "Epoch: 35\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 35 \tTraining Loss: 0.006638391021018227 \tValidation Loss: 0.006723638623952866\n",
            "Epoch: 36\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 36 \tTraining Loss: 0.006106851984643274 \tValidation Loss: 0.006215756293386221\n",
            "Epoch: 37\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 37 \tTraining Loss: 0.005633737555601531 \tValidation Loss: 0.005744915222749114\n",
            "Epoch: 38\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 38 \tTraining Loss: 0.005206067632469866 \tValidation Loss: 0.0053328280337154865\n",
            "\n",
            "Epoch: 39 \tTraining Loss: 0.004820159791658322 \tValidation Loss: 0.004942370345816016\n",
            "Epoch: 40\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 40 \tTraining Loss: 0.00447061425074935 \tValidation Loss: 0.004590632626786828\n",
            "Epoch: 41\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 41 \tTraining Loss: 0.004158100863504741 \tValidation Loss: 0.004283875925466418\n",
            "Epoch: 42\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 42 \tTraining Loss: 0.0038818607701816494 \tValidation Loss: 0.004007655545137823\n",
            "Epoch: 43\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 43 \tTraining Loss: 0.0036255347723555234 \tValidation Loss: 0.003765379195101559\n",
            "Epoch: 44\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 44 \tTraining Loss: 0.0034087127359170052 \tValidation Loss: 0.003534596413373947\n",
            "Epoch: 45\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 45 \tTraining Loss: 0.003210227587260306 \tValidation Loss: 0.0033389627933502197\n",
            "Epoch: 46\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 46 \tTraining Loss: 0.0030286496427531042 \tValidation Loss: 0.0031561932992190123\n",
            "\n",
            "Epoch: 47 \tTraining Loss: 0.002869684197422531 \tValidation Loss: 0.0029978984966874123\n",
            "Epoch: 48\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 48 \tTraining Loss: 0.0027273028002430997 \tValidation Loss: 0.002857940853573382\n",
            "Epoch: 49\t100.00% complete. 0.77 seconds elapsed in epoch.\n",
            "Epoch: 49 \tTraining Loss: 0.002601517416122887 \tValidation Loss: 0.0027175722643733025\n",
            "Epoch: 50\t100.00% complete. 0.70 seconds elapsed in epoch.\n",
            "Epoch: 50 \tTraining Loss: 0.002482673515462213 \tValidation Loss: 0.002598164137452841\n",
            "Epoch: 51\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 51 \tTraining Loss: 0.0023779815399191445 \tValidation Loss: 0.0024946320336312056\n",
            "Epoch: 52\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 52 \tTraining Loss: 0.002283439260079629 \tValidation Loss: 0.0023889547446742654\n",
            "Epoch: 53\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 53 \tTraining Loss: 0.002192283928808239 \tValidation Loss: 0.0022985144751146436\n",
            "Epoch: 54\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 54 \tTraining Loss: 0.002110882746314423 \tValidation Loss: 0.00221843714825809\n",
            "Epoch: 55\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 55 \tTraining Loss: 0.0020320870098657906 \tValidation Loss: 0.002162247197702527\n",
            "Epoch: 56\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 56 \tTraining Loss: 0.0019646519795060158 \tValidation Loss: 0.002066583896521479\n",
            "Epoch: 57\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 57 \tTraining Loss: 0.001907753913352887 \tValidation Loss: 0.0019957030308432877\n",
            "Epoch: 58\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 58 \tTraining Loss: 0.0018445081918293403 \tValidation Loss: 0.0019299517152830958\n",
            "Epoch: 59\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 59 \tTraining Loss: 0.0017760765104968515 \tValidation Loss: 0.0018761324463412166\n",
            "\n",
            "Epoch: 60 \tTraining Loss: 0.0017302806890155706 \tValidation Loss: 0.0018145132926292717\n",
            "Epoch: 61\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 61 \tTraining Loss: 0.0016688659800113076 \tValidation Loss: 0.0017536635277792811\n",
            "Epoch: 62\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 62 \tTraining Loss: 0.0016161574490575327 \tValidation Loss: 0.0017024636617861688\n",
            "Epoch: 63\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 63 \tTraining Loss: 0.001566086688803302 \tValidation Loss: 0.0016461407067254186\n",
            "\n",
            "Epoch: 64 \tTraining Loss: 0.0015177221697134276 \tValidation Loss: 0.001607164042070508\n",
            "Epoch: 65\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 65 \tTraining Loss: 0.0014760637293673223 \tValidation Loss: 0.00154584227129817\n",
            "Epoch: 66\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 66 \tTraining Loss: 0.0014250618276289767 \tValidation Loss: 0.001524846360553056\n",
            "\n",
            "Epoch: 67 \tTraining Loss: 0.001389459027753522 \tValidation Loss: 0.0014557760441675782\n",
            "\n",
            "Epoch: 68 \tTraining Loss: 0.0013492689015240306 \tValidation Loss: 0.001413610065355897\n",
            "Epoch: 69\t100.00% complete. 0.74 seconds elapsed in epoch.\n",
            "Epoch: 69 \tTraining Loss: 0.0013127895589503977 \tValidation Loss: 0.0013928021653555334\n",
            "Epoch: 70\t100.00% complete. 0.65 seconds elapsed in epoch.\n",
            "Epoch: 70 \tTraining Loss: 0.0012659209638109638 \tValidation Loss: 0.0013305415050126612\n",
            "Epoch: 71\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 71 \tTraining Loss: 0.0012180528849259848 \tValidation Loss: 0.0012785173603333533\n",
            "Epoch: 72\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 72 \tTraining Loss: 0.001183958070921815 \tValidation Loss: 0.0012394427903927863\n",
            "Epoch: 73\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 73 \tTraining Loss: 0.00114857969715053 \tValidation Loss: 0.0012024472234770656\n",
            "Epoch: 74\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 74 \tTraining Loss: 0.0011071304292676763 \tValidation Loss: 0.0011615176335908473\n",
            "Epoch: 75\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 75 \tTraining Loss: 0.001070736829812328 \tValidation Loss: 0.0011225554044358432\n",
            "Epoch: 76\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 76 \tTraining Loss: 0.0010382660774565819 \tValidation Loss: 0.0010883332579396665\n",
            "Epoch: 77\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 77 \tTraining Loss: 0.0010010709423416604 \tValidation Loss: 0.0010736011317931116\n",
            "Epoch: 78\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 78 \tTraining Loss: 0.000972754341394951 \tValidation Loss: 0.001020304363919422\n",
            "Epoch: 79\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 79 \tTraining Loss: 0.0009400207523463501 \tValidation Loss: 0.0009859624260570854\n",
            "Epoch: 80\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 80 \tTraining Loss: 0.0009079795013854487 \tValidation Loss: 0.0009613024303689599\n",
            "Epoch: 81\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 81 \tTraining Loss: 0.0008758416677462972 \tValidation Loss: 0.0009195985330734402\n",
            "Epoch: 82\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 82 \tTraining Loss: 0.000851099954969767 \tValidation Loss: 0.000889724848093465\n",
            "Epoch: 83\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 83 \tTraining Loss: 0.0008199891502348086 \tValidation Loss: 0.0008630096854176372\n",
            "Epoch: 84\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 84 \tTraining Loss: 0.0007919776382752591 \tValidation Loss: 0.0008294006402138621\n",
            "Epoch: 85\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 85 \tTraining Loss: 0.0007644512807019055 \tValidation Loss: 0.0008032425830606371\n",
            "Epoch: 86\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 86 \tTraining Loss: 0.0007344498331399842 \tValidation Loss: 0.0007745628245174885\n",
            "Epoch: 87\t100.00% complete. 0.58 seconds elapsed in epoch.\n",
            "Epoch: 87 \tTraining Loss: 0.0007107275758042104 \tValidation Loss: 0.0007516131736338139\n",
            "Epoch: 88\t100.00% complete. 0.78 seconds elapsed in epoch.\n",
            "Epoch: 88 \tTraining Loss: 0.000685510911150939 \tValidation Loss: 0.000748342921724543\n",
            "\n",
            "Epoch: 89 \tTraining Loss: 0.0006656726473011076 \tValidation Loss: 0.0007077570771798491\n",
            "Epoch: 90\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 90 \tTraining Loss: 0.0006388478601972262 \tValidation Loss: 0.0006733941845595837\n",
            "Epoch: 91\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 91 \tTraining Loss: 0.0006159282477003419 \tValidation Loss: 0.0006532850675284863\n",
            "\n",
            "Epoch: 92 \tTraining Loss: 0.0005948148706617454 \tValidation Loss: 0.0006279877852648497\n",
            "Epoch: 93\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 93 \tTraining Loss: 0.00057338145820217 \tValidation Loss: 0.0006065447232685983\n",
            "Epoch: 94\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 94 \tTraining Loss: 0.0005533460757255347 \tValidation Loss: 0.0005908182647544891\n",
            "\n",
            "Epoch: 95 \tTraining Loss: 0.0005337681133015496 \tValidation Loss: 0.0005697974993381649\n",
            "Epoch: 96\t100.00% complete. 0.59 seconds elapsed in epoch.\n",
            "Epoch: 96 \tTraining Loss: 0.0005183426288163497 \tValidation Loss: 0.0005653525877278298\n",
            "Epoch: 97\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 97 \tTraining Loss: 0.000502864662040439 \tValidation Loss: 0.000530342134879902\n",
            "Epoch: 98\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 98 \tTraining Loss: 0.0004815676576173347 \tValidation Loss: 0.0005202587926760316\n",
            "Epoch: 99\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 99 \tTraining Loss: 0.00046676310173804976 \tValidation Loss: 0.0004951150040142238\n",
            "Epoch: 100\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 100 \tTraining Loss: 0.0004499802469379372 \tValidation Loss: 0.0004755852132802829\n",
            "Epoch: 101\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 101 \tTraining Loss: 0.00043272207484632317 \tValidation Loss: 0.00046068851952441037\n",
            "Epoch: 102\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 102 \tTraining Loss: 0.00041744625034172915 \tValidation Loss: 0.0004493371961871162\n",
            "Epoch: 103\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 103 \tTraining Loss: 0.00040281205050026375 \tValidation Loss: 0.0004423666832735762\n",
            "Epoch: 104\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 104 \tTraining Loss: 0.0003943266347050667 \tValidation Loss: 0.00042639762978069484\n",
            "Epoch: 105\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 105 \tTraining Loss: 0.0003793521286247091 \tValidation Loss: 0.00040246336720883846\n",
            "Epoch: 106\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 106 \tTraining Loss: 0.0003664969424587778 \tValidation Loss: 0.00038826209492981434\n",
            "\n",
            "Epoch: 107 \tTraining Loss: 0.00035170964838471264 \tValidation Loss: 0.0003846231411444023\n",
            "Epoch: 108\t100.00% complete. 0.79 seconds elapsed in epoch.\n",
            "Epoch: 108 \tTraining Loss: 0.00034264544147946354 \tValidation Loss: 0.00036614011332858354\n",
            "Epoch: 109\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 109 \tTraining Loss: 0.0003331735319483818 \tValidation Loss: 0.00035618430410977453\n",
            "Epoch: 110\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 110 \tTraining Loss: 0.00032013078291331313 \tValidation Loss: 0.00034366037289146334\n",
            "Epoch: 111\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 111 \tTraining Loss: 0.0003074846810907022 \tValidation Loss: 0.00033033674117177725\n",
            "Epoch: 112\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 112 \tTraining Loss: 0.00029661016499934095 \tValidation Loss: 0.00032132833439391106\n",
            "Epoch: 113\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 113 \tTraining Loss: 0.0002873860018250222 \tValidation Loss: 0.0003109256795141846\n",
            "Epoch: 114\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 114 \tTraining Loss: 0.0002796580940614351 \tValidation Loss: 0.00030122486350592226\n",
            "Epoch: 115\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 115 \tTraining Loss: 0.00027020849504171766 \tValidation Loss: 0.00029325811192393303\n",
            "Epoch: 116\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 116 \tTraining Loss: 0.00026242798048770055 \tValidation Loss: 0.0002837013016687706\n",
            "Epoch: 117\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 117 \tTraining Loss: 0.00025402738780636963 \tValidation Loss: 0.00028109394770581275\n",
            "Epoch: 118\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 118 \tTraining Loss: 0.0002474624011988959 \tValidation Loss: 0.0002676219883142039\n",
            "Epoch: 119\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 119 \tTraining Loss: 0.00023909346459226476 \tValidation Loss: 0.00026013574097305536\n",
            "\n",
            "Epoch: 120 \tTraining Loss: 0.00023056066371888542 \tValidation Loss: 0.000251597142778337\n",
            "Epoch: 121\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 121 \tTraining Loss: 0.0002246756177757763 \tValidation Loss: 0.00024616286100354046\n",
            "Epoch: 122\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 122 \tTraining Loss: 0.00022078948030765686 \tValidation Loss: 0.0002419376469333656\n",
            "Epoch: 123\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 123 \tTraining Loss: 0.0002118490067207151 \tValidation Loss: 0.00023156480165198445\n",
            "Epoch: 124\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 124 \tTraining Loss: 0.0002063886074918426 \tValidation Loss: 0.0002269082615384832\n",
            "Epoch: 125\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 125 \tTraining Loss: 0.00020054170454386622 \tValidation Loss: 0.00022060005721868947\n",
            "Epoch: 126\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 126 \tTraining Loss: 0.00019355903431359265 \tValidation Loss: 0.00021446885511977598\n",
            "Epoch: 127\t100.00% complete. 0.78 seconds elapsed in epoch.\n",
            "Epoch: 127 \tTraining Loss: 0.00018820458596261838 \tValidation Loss: 0.00020669343939516693\n",
            "Epoch: 128\t100.00% complete. 0.66 seconds elapsed in epoch.\n",
            "Epoch: 128 \tTraining Loss: 0.00018324328347161 \tValidation Loss: 0.0002008887313422747\n",
            "Epoch: 129\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 129 \tTraining Loss: 0.00017865329896772487 \tValidation Loss: 0.00019783830794040114\n",
            "Epoch: 130\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 130 \tTraining Loss: 0.00017373403372605227 \tValidation Loss: 0.00019088201952399686\n",
            "Epoch: 131\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 131 \tTraining Loss: 0.00016846379811694432 \tValidation Loss: 0.0001861081473180093\n",
            "Epoch: 132\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 132 \tTraining Loss: 0.0001639056030803153 \tValidation Loss: 0.00018143146735383198\n",
            "Epoch: 133\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 133 \tTraining Loss: 0.00015958126621424325 \tValidation Loss: 0.00017844334070105106\n",
            "Epoch: 134\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 134 \tTraining Loss: 0.00015610764886433672 \tValidation Loss: 0.00017198618297697976\n",
            "\n",
            "Epoch: 135 \tTraining Loss: 0.0001512329027819861 \tValidation Loss: 0.00016735791723476723\n",
            "Epoch: 136\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 136 \tTraining Loss: 0.00014707628280221898 \tValidation Loss: 0.0001636481611058116\n",
            "\n",
            "Epoch: 137 \tTraining Loss: 0.0001438247268702576 \tValidation Loss: 0.00015931828238535672\n",
            "Epoch: 138\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 138 \tTraining Loss: 0.00014036392409858914 \tValidation Loss: 0.0001566941646160558\n",
            "Epoch: 139\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 139 \tTraining Loss: 0.0001401996511655549 \tValidation Loss: 0.0001523351893411018\n",
            "Epoch: 140\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 140 \tTraining Loss: 0.00013280789587750204 \tValidation Loss: 0.0001487767367507331\n",
            "Epoch: 141\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 141 \tTraining Loss: 0.00012929754019650217 \tValidation Loss: 0.0001444162116968073\n",
            "Epoch: 142\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 142 \tTraining Loss: 0.00012574610688413182 \tValidation Loss: 0.00014121902495389804\n",
            "Epoch: 143\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 143 \tTraining Loss: 0.00012352189797739912 \tValidation Loss: 0.0001370219179079868\n",
            "Epoch: 144\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 144 \tTraining Loss: 0.00012151260307291523 \tValidation Loss: 0.0001350084421574138\n",
            "Epoch: 145\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 145 \tTraining Loss: 0.00011794479036729576 \tValidation Loss: 0.00013089756976114586\n",
            "Epoch: 146\t100.00% complete. 0.68 seconds elapsed in epoch.\n",
            "Epoch: 146 \tTraining Loss: 0.00011473194131718224 \tValidation Loss: 0.0001299981668125838\n",
            "\n",
            "Epoch: 147 \tTraining Loss: 0.00011273184564844187 \tValidation Loss: 0.0001240922138094902\n",
            "Epoch: 148\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 148 \tTraining Loss: 0.00010867546249452668 \tValidation Loss: 0.0001228779619850684\n",
            "Epoch: 149\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 149 \tTraining Loss: 0.00010624838655025492 \tValidation Loss: 0.00012116256766603328\n",
            "Epoch: 150\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 150 \tTraining Loss: 0.00010447859515099683 \tValidation Loss: 0.00011742152128135785\n",
            "\n",
            "Epoch: 151 \tTraining Loss: 0.00010176301131852799 \tValidation Loss: 0.00011360109056113288\n",
            "Epoch: 152\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 152 \tTraining Loss: 9.984713243385259e-05 \tValidation Loss: 0.00011075408838223666\n",
            "\n",
            "Epoch: 153 \tTraining Loss: 9.818828281519625e-05 \tValidation Loss: 0.00010960247891489416\n",
            "Epoch: 154\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 154 \tTraining Loss: 9.475315002621048e-05 \tValidation Loss: 0.00010776380804600194\n",
            "Epoch: 155\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 155 \tTraining Loss: 9.25664325121842e-05 \tValidation Loss: 0.00010420945909572765\n",
            "Epoch: 156\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 156 \tTraining Loss: 9.1732039840685e-05 \tValidation Loss: 0.00010261281204293482\n",
            "Epoch: 157\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 157 \tTraining Loss: 8.908610026183951e-05 \tValidation Loss: 9.918719297274947e-05\n",
            "Epoch: 158\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 158 \tTraining Loss: 8.653179934804534e-05 \tValidation Loss: 9.780501932254992e-05\n",
            "Epoch: 159\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 159 \tTraining Loss: 8.462240212894458e-05 \tValidation Loss: 9.780889740795828e-05\n",
            "Epoch: 160\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 160 \tTraining Loss: 8.35535546583641e-05 \tValidation Loss: 9.348844469059259e-05\n",
            "Epoch: 161\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 161 \tTraining Loss: 8.09257027059276e-05 \tValidation Loss: 9.119490277953446e-05\n",
            "Epoch: 162\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 162 \tTraining Loss: 7.973858272533916e-05 \tValidation Loss: 8.932080163503997e-05\n",
            "Epoch: 163\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 163 \tTraining Loss: 7.781122136899891e-05 \tValidation Loss: 8.812352825771086e-05\n",
            "Epoch: 164\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 164 \tTraining Loss: 7.62273642370322e-05 \tValidation Loss: 8.615087426733226e-05\n",
            "Epoch: 165\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 165 \tTraining Loss: 7.480205951853552e-05 \tValidation Loss: 8.432990944129415e-05\n",
            "Epoch: 166\t100.00% complete. 0.78 seconds elapsed in epoch.\n",
            "Epoch: 166 \tTraining Loss: 7.327880949661549e-05 \tValidation Loss: 8.258047819253989e-05\n",
            "Epoch: 167\t100.00% complete. 0.70 seconds elapsed in epoch.\n",
            "Epoch: 167 \tTraining Loss: 7.180997029839394e-05 \tValidation Loss: 8.106477616820484e-05\n",
            "Epoch: 168\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 168 \tTraining Loss: 7.080922680163187e-05 \tValidation Loss: 8.09814919193741e-05\n",
            "Epoch: 169\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 169 \tTraining Loss: 7.002773862849508e-05 \tValidation Loss: 7.789460505591705e-05\n",
            "Epoch: 170\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 170 \tTraining Loss: 6.80382268506542e-05 \tValidation Loss: 7.630264735780656e-05\n",
            "Epoch: 171\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 171 \tTraining Loss: 6.683292101822897e-05 \tValidation Loss: 7.532453673775308e-05\n",
            "\n",
            "Epoch: 172 \tTraining Loss: 6.698470173836945e-05 \tValidation Loss: 7.340946103795432e-05\n",
            "Epoch: 173\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 173 \tTraining Loss: 6.631658996209606e-05 \tValidation Loss: 7.455916056642309e-05\n",
            "Epoch: 174\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 174 \tTraining Loss: 6.424398775885088e-05 \tValidation Loss: 7.04015874362085e-05\n",
            "Epoch: 175\t100.00% complete. 0.58 seconds elapsed in epoch.\n",
            "Epoch: 175 \tTraining Loss: 6.320000749029632e-05 \tValidation Loss: 7.272051880136132e-05\n",
            "\n",
            "Epoch: 176 \tTraining Loss: 6.148030095371521e-05 \tValidation Loss: 6.926312198629603e-05\n",
            "Epoch: 177\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 177 \tTraining Loss: 5.9746766863908204e-05 \tValidation Loss: 6.739948366885073e-05\n",
            "Epoch: 178\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 178 \tTraining Loss: 5.891878532161677e-05 \tValidation Loss: 6.622068758588284e-05\n",
            "Epoch: 179\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 179 \tTraining Loss: 5.77696490735333e-05 \tValidation Loss: 6.497911454061978e-05\n",
            "Epoch: 180\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 180 \tTraining Loss: 5.718769332613899e-05 \tValidation Loss: 6.481607488240115e-05\n",
            "Epoch: 181\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 181 \tTraining Loss: 5.6057314092565015e-05 \tValidation Loss: 6.30701888439944e-05\n",
            "Epoch: 182\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 182 \tTraining Loss: 5.593559439552741e-05 \tValidation Loss: 6.224307435331866e-05\n",
            "Epoch: 183\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 183 \tTraining Loss: 5.3958220329756536e-05 \tValidation Loss: 6.0848065913887694e-05\n",
            "Epoch: 184\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 184 \tTraining Loss: 5.4009025916457176e-05 \tValidation Loss: 6.0913236666237935e-05\n",
            "Epoch: 185\t100.00% complete. 0.77 seconds elapsed in epoch.\n",
            "Epoch: 185 \tTraining Loss: 5.2739081082917335e-05 \tValidation Loss: 5.8649620768846944e-05\n",
            "Epoch: 186\t100.00% complete. 0.69 seconds elapsed in epoch.\n",
            "Epoch: 186 \tTraining Loss: 5.1417923209050466e-05 \tValidation Loss: 5.762088949268218e-05\n",
            "Epoch: 187\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 187 \tTraining Loss: 5.1275814864008375e-05 \tValidation Loss: 5.7203553296858445e-05\n",
            "Epoch: 188\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 188 \tTraining Loss: 5.068991049483884e-05 \tValidation Loss: 5.6446036978741176e-05\n",
            "Epoch: 189\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 189 \tTraining Loss: 4.9686838893750166e-05 \tValidation Loss: 5.651895116898231e-05\n",
            "Epoch: 190\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 190 \tTraining Loss: 4.847106639418699e-05 \tValidation Loss: 5.436752144305501e-05\n",
            "Epoch: 191\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 191 \tTraining Loss: 4.798649752046913e-05 \tValidation Loss: 5.444672751764301e-05\n",
            "Epoch: 192\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 192 \tTraining Loss: 4.821087309715545e-05 \tValidation Loss: 5.381146002036985e-05\n",
            "\n",
            "Epoch: 193 \tTraining Loss: 4.709467935349999e-05 \tValidation Loss: 5.195854100747965e-05\n",
            "Epoch: 194\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 194 \tTraining Loss: 4.627526989982774e-05 \tValidation Loss: 5.119495835970156e-05\n",
            "\n",
            "Epoch: 195 \tTraining Loss: 4.544976016202579e-05 \tValidation Loss: 5.070900442660786e-05\n",
            "Epoch: 196\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 196 \tTraining Loss: 4.5212610631198106e-05 \tValidation Loss: 5.032846638641786e-05\n",
            "Epoch: 197\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 197 \tTraining Loss: 4.482343239134126e-05 \tValidation Loss: 4.982865539204795e-05\n",
            "Epoch: 198\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 198 \tTraining Loss: 4.384465501061641e-05 \tValidation Loss: 4.8632222387823276e-05\n",
            "Epoch: 199\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 199 \tTraining Loss: 4.3976390265419875e-05 \tValidation Loss: 5.088263424113393e-05\n",
            "Epoch: 200\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 200 \tTraining Loss: 4.3859891876410176e-05 \tValidation Loss: 4.897685539617669e-05\n",
            "\n",
            "Epoch: 201 \tTraining Loss: 4.2800144001375884e-05 \tValidation Loss: 4.665294000005815e-05\n",
            "Epoch: 202\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 202 \tTraining Loss: 4.257965378605554e-05 \tValidation Loss: 4.815505781152751e-05\n",
            "Epoch: 203\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 203 \tTraining Loss: 4.2020969582760394e-05 \tValidation Loss: 4.655413613363635e-05\n",
            "\n",
            "Epoch: 204 \tTraining Loss: 4.0385784612024305e-05 \tValidation Loss: 4.460744094103575e-05\n",
            "Epoch: 205\t100.00% complete. 0.74 seconds elapsed in epoch.\n",
            "Epoch: 205 \tTraining Loss: 4.049601597620899e-05 \tValidation Loss: 4.456356509763282e-05\n",
            "Epoch: 206\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 206 \tTraining Loss: 3.979596921352721e-05 \tValidation Loss: 4.3415471736807376e-05\n",
            "Epoch: 207\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 207 \tTraining Loss: 3.9641872515656156e-05 \tValidation Loss: 4.3076410292997025e-05\n",
            "Epoch: 208\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 208 \tTraining Loss: 3.867350500917787e-05 \tValidation Loss: 4.2788966311491095e-05\n",
            "Epoch: 209\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 209 \tTraining Loss: 3.879616047520863e-05 \tValidation Loss: 4.190211620880291e-05\n",
            "Epoch: 210\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 210 \tTraining Loss: 3.79943216507349e-05 \tValidation Loss: 4.1377941670361906e-05\n",
            "Epoch: 211\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 211 \tTraining Loss: 3.7352799457342677e-05 \tValidation Loss: 4.113978138775565e-05\n",
            "Epoch: 212\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 212 \tTraining Loss: 3.7015996389931795e-05 \tValidation Loss: 4.072928459208924e-05\n",
            "\n",
            "Epoch: 213 \tTraining Loss: 3.6479428066134766e-05 \tValidation Loss: 4.075400465808343e-05\n",
            "Epoch: 214\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 214 \tTraining Loss: 3.662267671542294e-05 \tValidation Loss: 4.1047380364034325e-05\n",
            "\n",
            "Epoch: 215 \tTraining Loss: 3.639642697332116e-05 \tValidation Loss: 4.169433668721467e-05\n",
            "Epoch: 216\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 216 \tTraining Loss: 3.6471510409480994e-05 \tValidation Loss: 4.125173654756509e-05\n",
            "Epoch: 217\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 217 \tTraining Loss: 3.576550352590857e-05 \tValidation Loss: 3.878768620779738e-05\n",
            "Epoch: 218\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 218 \tTraining Loss: 3.475131941538873e-05 \tValidation Loss: 3.810921771219e-05\n",
            "Epoch: 219\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 219 \tTraining Loss: 3.4377551653758725e-05 \tValidation Loss: 3.721634311659727e-05\n",
            "Epoch: 220\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 220 \tTraining Loss: 3.4068417032055244e-05 \tValidation Loss: 3.712564466695767e-05\n",
            "\n",
            "Epoch: 221 \tTraining Loss: 3.365634377890577e-05 \tValidation Loss: 3.6982040910515934e-05\n",
            "Epoch: 222\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 222 \tTraining Loss: 3.374855158553045e-05 \tValidation Loss: 3.7125524613657035e-05\n",
            "Epoch: 223\t100.00% complete. 0.61 seconds elapsed in epoch.\n",
            "Epoch: 223 \tTraining Loss: 3.347189390802264e-05 \tValidation Loss: 3.5901961382478476e-05\n",
            "Epoch: 224\t100.00% complete. 0.75 seconds elapsed in epoch.\n",
            "Epoch: 224 \tTraining Loss: 3.294063824594357e-05 \tValidation Loss: 3.619132985477336e-05\n",
            "Epoch: 225\t100.00% complete. 0.65 seconds elapsed in epoch.\n",
            "Epoch: 225 \tTraining Loss: 3.2570257947857804e-05 \tValidation Loss: 3.5595634471974336e-05\n",
            "\n",
            "Epoch: 226 \tTraining Loss: 3.272496168291481e-05 \tValidation Loss: 3.507197652652394e-05\n",
            "Epoch: 227\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 227 \tTraining Loss: 3.187365655321628e-05 \tValidation Loss: 3.4612314266269095e-05\n",
            "Epoch: 228\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 228 \tTraining Loss: 3.1653697280691835e-05 \tValidation Loss: 3.5666180338012055e-05\n",
            "\n",
            "Epoch: 229 \tTraining Loss: 3.151349705553407e-05 \tValidation Loss: 3.404881317692343e-05\n",
            "Epoch: 230\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 230 \tTraining Loss: 3.1364091733444686e-05 \tValidation Loss: 3.3562771932338364e-05\n",
            "Epoch: 231\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 231 \tTraining Loss: 3.062613622104335e-05 \tValidation Loss: 3.329877472424414e-05\n",
            "Epoch: 232\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 232 \tTraining Loss: 3.094444602740825e-05 \tValidation Loss: 3.3613569030421786e-05\n",
            "Epoch: 233\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 233 \tTraining Loss: 3.0091263195370426e-05 \tValidation Loss: 3.255140472901985e-05\n",
            "Epoch: 234\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 234 \tTraining Loss: 3.000656276223405e-05 \tValidation Loss: 3.223614112357609e-05\n",
            "Epoch: 235\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 235 \tTraining Loss: 2.9814596119750706e-05 \tValidation Loss: 3.238560566387605e-05\n",
            "Epoch: 236\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 236 \tTraining Loss: 3.0161088135274542e-05 \tValidation Loss: 3.151471355522517e-05\n",
            "Epoch: 237\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 237 \tTraining Loss: 2.9230084692244418e-05 \tValidation Loss: 3.222131635993719e-05\n",
            "Epoch: 238\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 238 \tTraining Loss: 2.8853727498143497e-05 \tValidation Loss: 3.111822843493428e-05\n",
            "Epoch: 239\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 239 \tTraining Loss: 2.8631683360597686e-05 \tValidation Loss: 3.0795748898526654e-05\n",
            "Epoch: 240\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 240 \tTraining Loss: 2.8529789031179258e-05 \tValidation Loss: 3.1876275897957385e-05\n",
            "Epoch: 241\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 241 \tTraining Loss: 2.8238752646656292e-05 \tValidation Loss: 3.0372009860002436e-05\n",
            "Epoch: 242\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 242 \tTraining Loss: 2.804398981323983e-05 \tValidation Loss: 2.9918131076556165e-05\n",
            "Epoch: 243\t100.00% complete. 0.73 seconds elapsed in epoch.\n",
            "Epoch: 243 \tTraining Loss: 2.765235421975376e-05 \tValidation Loss: 2.962508278869791e-05\n",
            "\n",
            "Epoch: 244 \tTraining Loss: 2.7814443658118966e-05 \tValidation Loss: 3.0385285754164215e-05\n",
            "Epoch: 245\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 245 \tTraining Loss: 2.708134181577609e-05 \tValidation Loss: 2.9134036594768986e-05\n",
            "Epoch: 246\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 246 \tTraining Loss: 2.7354605461166808e-05 \tValidation Loss: 2.8515492886072025e-05\n",
            "Epoch: 247\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 247 \tTraining Loss: 2.6686476505549057e-05 \tValidation Loss: 2.9766255465801805e-05\n",
            "Epoch: 248\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 248 \tTraining Loss: 2.7010999272331697e-05 \tValidation Loss: 2.8125923563493416e-05\n",
            "Epoch: 249\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 249 \tTraining Loss: 2.7289803155225753e-05 \tValidation Loss: 3.0808851988695096e-05\n",
            "Epoch: 250\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 250 \tTraining Loss: 2.7358007981901108e-05 \tValidation Loss: 2.855166076187743e-05\n",
            "\n",
            "Epoch: 251 \tTraining Loss: 2.785612155599261e-05 \tValidation Loss: 3.0189790777512826e-05\n",
            "Epoch: 252\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 252 \tTraining Loss: 2.6078594297966145e-05 \tValidation Loss: 2.7104710170533508e-05\n",
            "\n",
            "Epoch: 253 \tTraining Loss: 2.500297755937532e-05 \tValidation Loss: 2.6748180971480906e-05\n",
            "Epoch: 254\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 254 \tTraining Loss: 2.479349233100139e-05 \tValidation Loss: 2.643348943820456e-05\n",
            "Epoch: 255\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 255 \tTraining Loss: 2.548086164703515e-05 \tValidation Loss: 2.6809899281943217e-05\n",
            "Epoch: 256\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 256 \tTraining Loss: 2.6328477057783555e-05 \tValidation Loss: 2.808751742122695e-05\n",
            "Epoch: 257\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 257 \tTraining Loss: 2.4350526574481693e-05 \tValidation Loss: 2.6651588996173814e-05\n",
            "Epoch: 258\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 258 \tTraining Loss: 2.4141614327769883e-05 \tValidation Loss: 2.5833940526354127e-05\n",
            "Epoch: 259\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 259 \tTraining Loss: 2.4046548484572366e-05 \tValidation Loss: 2.5429052584513556e-05\n",
            "Epoch: 260\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 260 \tTraining Loss: 2.3675021717887528e-05 \tValidation Loss: 2.5768583327590022e-05\n",
            "Epoch: 261\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 261 \tTraining Loss: 2.4634235160192475e-05 \tValidation Loss: 2.4463151930831373e-05\n",
            "Epoch: 262\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 262 \tTraining Loss: 2.348407522529467e-05 \tValidation Loss: 2.4695179490663577e-05\n",
            "\n",
            "Epoch: 263 \tTraining Loss: 2.30795285460772e-05 \tValidation Loss: 2.422943271085387e-05\n",
            "Epoch: 264\t100.00% complete. 0.70 seconds elapsed in epoch.\n",
            "Epoch: 264 \tTraining Loss: 2.289661541807517e-05 \tValidation Loss: 2.393020986346528e-05\n",
            "\n",
            "Epoch: 265 \tTraining Loss: 2.2472741066950322e-05 \tValidation Loss: 2.5141839614661876e-05\n",
            "Epoch: 266\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 266 \tTraining Loss: 2.249468242452066e-05 \tValidation Loss: 2.4307136300194543e-05\n",
            "Epoch: 267\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 267 \tTraining Loss: 2.2369670356662635e-05 \tValidation Loss: 2.3861047338868957e-05\n",
            "Epoch: 268\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 268 \tTraining Loss: 2.225738858720029e-05 \tValidation Loss: 2.537196814955678e-05\n",
            "Epoch: 269\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 269 \tTraining Loss: 2.2212799801006138e-05 \tValidation Loss: 2.2867553525429685e-05\n",
            "\n",
            "Epoch: 270 \tTraining Loss: 2.191192551334906e-05 \tValidation Loss: 2.3707455511612352e-05\n",
            "Epoch: 271\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 271 \tTraining Loss: 2.159821168687712e-05 \tValidation Loss: 2.2983945200394373e-05\n",
            "Epoch: 272\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 272 \tTraining Loss: 2.171062341302685e-05 \tValidation Loss: 2.2222289771889336e-05\n",
            "Epoch: 273\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 273 \tTraining Loss: 2.0956382488495568e-05 \tValidation Loss: 2.2066738893045112e-05\n",
            "\n",
            "Epoch: 274 \tTraining Loss: 2.1085994376335293e-05 \tValidation Loss: 2.1617785932903644e-05\n",
            "Epoch: 275\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 275 \tTraining Loss: 2.0777176865117832e-05 \tValidation Loss: 2.2176144739205483e-05\n",
            "Epoch: 276\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 276 \tTraining Loss: 2.046969843326628e-05 \tValidation Loss: 2.1482419469975866e-05\n",
            "Epoch: 277\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 277 \tTraining Loss: 2.0436981079304434e-05 \tValidation Loss: 2.1032860786363017e-05\n",
            "Epoch: 278\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 278 \tTraining Loss: 2.0353581122536627e-05 \tValidation Loss: 2.118757493008161e-05\n",
            "Epoch: 279\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 279 \tTraining Loss: 2.0601201362700926e-05 \tValidation Loss: 2.0544241124298424e-05\n",
            "Epoch: 280\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 280 \tTraining Loss: 1.9625234825879386e-05 \tValidation Loss: 2.102349480992416e-05\n",
            "Epoch: 281\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 281 \tTraining Loss: 1.9998096124456628e-05 \tValidation Loss: 2.1266208023007493e-05\n",
            "Epoch: 282\t100.00% complete. 0.61 seconds elapsed in epoch.\n",
            "Epoch: 282 \tTraining Loss: 1.9693450465436195e-05 \tValidation Loss: 2.175350527977571e-05\n",
            "Epoch: 283\t100.00% complete. 0.75 seconds elapsed in epoch.\n",
            "Epoch: 283 \tTraining Loss: 1.9398842495219367e-05 \tValidation Loss: 2.0058785594301298e-05\n",
            "Epoch: 284\t100.00% complete. 0.66 seconds elapsed in epoch.\n",
            "Epoch: 284 \tTraining Loss: 1.933243432479988e-05 \tValidation Loss: 2.3854576284065843e-05\n",
            "Epoch: 285\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 285 \tTraining Loss: 2.004974501485574e-05 \tValidation Loss: 1.9631878785730805e-05\n",
            "Epoch: 286\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 286 \tTraining Loss: 1.8724314840154773e-05 \tValidation Loss: 1.9328424059494864e-05\n",
            "Epoch: 287\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 287 \tTraining Loss: 1.8526091783617932e-05 \tValidation Loss: 1.932320537889609e-05\n",
            "Epoch: 288\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 288 \tTraining Loss: 1.8295956376985283e-05 \tValidation Loss: 1.9474355212878436e-05\n",
            "Epoch: 289\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 289 \tTraining Loss: 1.8343383291923805e-05 \tValidation Loss: 1.8737624486675486e-05\n",
            "Epoch: 290\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 290 \tTraining Loss: 1.8025313086885337e-05 \tValidation Loss: 1.9069606423727237e-05\n",
            "Epoch: 291\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 291 \tTraining Loss: 1.80130327862571e-05 \tValidation Loss: 2.0933575797243975e-05\n",
            "Epoch: 292\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 292 \tTraining Loss: 1.9301451478289284e-05 \tValidation Loss: 1.9872298253176268e-05\n",
            "Epoch: 293\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 293 \tTraining Loss: 1.8299670147017525e-05 \tValidation Loss: 1.8316531168238726e-05\n",
            "\n",
            "Epoch: 294 \tTraining Loss: 1.812816076886116e-05 \tValidation Loss: 1.8664780327526387e-05\n",
            "Epoch: 295\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 295 \tTraining Loss: 1.7451769811790047e-05 \tValidation Loss: 1.7950861547433306e-05\n",
            "Epoch: 296\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 296 \tTraining Loss: 1.7022018305902344e-05 \tValidation Loss: 1.8090671801473945e-05\n",
            "Epoch: 297\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 297 \tTraining Loss: 1.741888162440672e-05 \tValidation Loss: 1.7323301108262967e-05\n",
            "\n",
            "Epoch: 298 \tTraining Loss: 1.6721622210348465e-05 \tValidation Loss: 1.7685444618109614e-05\n",
            "Epoch: 299\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 299 \tTraining Loss: 1.7036411009030417e-05 \tValidation Loss: 1.786597476893803e-05\n",
            "175.89 total seconds elapsed. 0.59 seconds per epoch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the solution learnt from SIREN\n",
        "t = t.view(-1, 1)\n",
        "times, model_outputs = evaluate(model, t)\n",
        "\n",
        "plot_outputs(times, model_outputs, solution_to_ODE(times))"
      ],
      "metadata": {
        "id": "wXj3oYC423m1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "14c6d08f-9ddf-416c-f44e-4fbdbbfef211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing and training a model with tanh activations. Note although the network is still name SIREN,\n",
        "# the below model uses only tanh activations\n",
        "\n",
        "tanh_model = Siren(in_features=1, out_features=1, hidden_features=10,\n",
        "                  hidden_layers=10, outermost_linear=True, first_omega_0=1, hidden_omega_0=1,\n",
        "              activ=torch.tanh)\n",
        "if train_on_gpu:\n",
        "    tanh_model = tanh_model.to('cuda')\n",
        "\n",
        "optimizer = torch.optim.RAdam(tanh_model.parameters())\n",
        "tanh_model, tanh_losses = train(tanh_model, criteria, optimizer, dataloaders['train'], dataloaders['val'], 300)"
      ],
      "metadata": {
        "id": "KVT1Ty7QZoYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b308789-da41-45de-8bbd-31c69febace0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\t100.00% complete. 0.73 seconds elapsed in epoch.\n",
            "Epoch: 0 \tTraining Loss: 4.123962998390198 \tValidation Loss: 0.8065412044525146\n",
            "Epoch: 1\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 1 \tTraining Loss: 0.7677188681231605 \tValidation Loss: 0.8054371476173401\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 0.7644937766922845 \tValidation Loss: 0.8049760162830353\n",
            "Epoch: 3\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 3 \tTraining Loss: 0.7619088755713569 \tValidation Loss: 0.8050826191902161\n",
            "Epoch: 4\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 4 \tTraining Loss: 0.759540554549959 \tValidation Loss: 0.8056672513484955\n",
            "Epoch: 5\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 5 \tTraining Loss: 0.757964379257626 \tValidation Loss: 0.8065955340862274\n",
            "Epoch: 6\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 6 \tTraining Loss: 0.7569340202543471 \tValidation Loss: 0.807515025138855\n",
            "Epoch: 7\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 7 \tTraining Loss: 0.7563157942559984 \tValidation Loss: 0.8081397116184235\n",
            "Epoch: 8\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 8 \tTraining Loss: 0.7559030254681905 \tValidation Loss: 0.8086040019989014\n",
            "Epoch: 9\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 9 \tTraining Loss: 0.7552094227737851 \tValidation Loss: 0.8081541359424591\n",
            "Epoch: 10\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 10 \tTraining Loss: 0.7540499932236142 \tValidation Loss: 0.8065651059150696\n",
            "Epoch: 11\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 11 \tTraining Loss: 0.7510707676410675 \tValidation Loss: 0.800497442483902\n",
            "Epoch: 12\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 12 \tTraining Loss: 0.7429394258393182 \tValidation Loss: 0.7837763428688049\n",
            "Epoch: 13\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 13 \tTraining Loss: 0.7189887960751852 \tValidation Loss: 0.7388525009155273\n",
            "Epoch: 14\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 14 \tTraining Loss: 0.6546313597096337 \tValidation Loss: 0.6244642436504364\n",
            "\n",
            "Epoch: 15 \tTraining Loss: 0.4846404691537221 \tValidation Loss: 0.35341762006282806\n",
            "Epoch: 16\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 16 \tTraining Loss: 0.2061302214860916 \tValidation Loss: 0.11875909939408302\n",
            "Epoch: 17\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 17 \tTraining Loss: 0.08155335175494353 \tValidation Loss: 0.05976937711238861\n",
            "Epoch: 18\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 18 \tTraining Loss: 0.048211452240745224 \tValidation Loss: 0.04422610253095627\n",
            "Epoch: 19\t100.00% complete. 0.48 seconds elapsed in epoch.\n",
            "Epoch: 19 \tTraining Loss: 0.03989495999283261 \tValidation Loss: 0.038190025836229324\n",
            "Epoch: 20\t100.00% complete. 0.76 seconds elapsed in epoch.\n",
            "Epoch: 20 \tTraining Loss: 0.0347813842818141 \tValidation Loss: 0.033206889405846596\n",
            "Epoch: 21\t100.00% complete. 0.73 seconds elapsed in epoch.\n",
            "Epoch: 21 \tTraining Loss: 0.030983190880053572 \tValidation Loss: 0.029658688232302666\n",
            "\n",
            "Epoch: 22 \tTraining Loss: 0.027988855209615495 \tValidation Loss: 0.026871275156736374\n",
            "Epoch: 23\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 23 \tTraining Loss: 0.02537911654346519 \tValidation Loss: 0.02459127362817526\n",
            "\n",
            "Epoch: 24 \tTraining Loss: 0.023021843801769946 \tValidation Loss: 0.02258016262203455\n",
            "Epoch: 25\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 25 \tTraining Loss: 0.02084578832404481 \tValidation Loss: 0.02071117516607046\n",
            "Epoch: 26\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 26 \tTraining Loss: 0.018980432560460433 \tValidation Loss: 0.019391962327063084\n",
            "Epoch: 27\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 27 \tTraining Loss: 0.01755413081910875 \tValidation Loss: 0.018382525071501732\n",
            "Epoch: 28\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 28 \tTraining Loss: 0.016448991942322917 \tValidation Loss: 0.017353463917970657\n",
            "Epoch: 29\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 29 \tTraining Loss: 0.01576048808379306 \tValidation Loss: 0.016765678767114878\n",
            "Epoch: 30\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 30 \tTraining Loss: 0.015375378903829388 \tValidation Loss: 0.01674567721784115\n",
            "Epoch: 31\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 31 \tTraining Loss: 0.015101719751126237 \tValidation Loss: 0.016350166872143745\n",
            "\n",
            "Epoch: 32 \tTraining Loss: 0.01473349193111062 \tValidation Loss: 0.01566259004175663\n",
            "Epoch: 33\t100.00% complete. 0.48 seconds elapsed in epoch.\n",
            "Epoch: 33 \tTraining Loss: 0.014158751349896193 \tValidation Loss: 0.014530051965266466\n",
            "Epoch: 34\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 34 \tTraining Loss: 0.01323370568247305 \tValidation Loss: 0.013412514235824347\n",
            "Epoch: 35\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 35 \tTraining Loss: 0.011912368496672975 \tValidation Loss: 0.011303439736366272\n",
            "Epoch: 36\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 36 \tTraining Loss: 0.009674907015222643 \tValidation Loss: 0.00851992703974247\n",
            "\n",
            "Epoch: 37 \tTraining Loss: 0.006617048962248696 \tValidation Loss: 0.00457311375066638\n",
            "Epoch: 38\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 38 \tTraining Loss: 0.003326960250787023 \tValidation Loss: 0.001786950509995222\n",
            "Epoch: 39\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 39 \tTraining Loss: 0.0011326264809920555 \tValidation Loss: 0.0004332285898271948\n",
            "Epoch: 40\t100.00% complete. 0.62 seconds elapsed in epoch.\n",
            "Epoch: 40 \tTraining Loss: 0.00032415724369154003 \tValidation Loss: 0.00020173329539829865\n",
            "Epoch: 41\t100.00% complete. 0.74 seconds elapsed in epoch.\n",
            "Epoch: 41 \tTraining Loss: 0.0001558413164780682 \tValidation Loss: 0.0001244345330633223\n",
            "Epoch: 42\t100.00% complete. 0.64 seconds elapsed in epoch.\n",
            "Epoch: 42 \tTraining Loss: 9.765773575054482e-05 \tValidation Loss: 6.441111327148974e-05\n",
            "Epoch: 43\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 43 \tTraining Loss: 6.43343315055568e-05 \tValidation Loss: 4.6606583055108786e-05\n",
            "Epoch: 44\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 44 \tTraining Loss: 5.045376504616191e-05 \tValidation Loss: 3.916621790267527e-05\n",
            "Epoch: 45\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 45 \tTraining Loss: 4.2380575501334126e-05 \tValidation Loss: 3.3715454264893197e-05\n",
            "Epoch: 46\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 46 \tTraining Loss: 3.49751544490573e-05 \tValidation Loss: 2.8068148822057992e-05\n",
            "Epoch: 47\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 47 \tTraining Loss: 3.11714036595529e-05 \tValidation Loss: 2.5230976461898535e-05\n",
            "Epoch: 48\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 48 \tTraining Loss: 2.8302826548396195e-05 \tValidation Loss: 2.3542080270999577e-05\n",
            "Epoch: 49\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 49 \tTraining Loss: 2.6651494812944697e-05 \tValidation Loss: 2.230786776635796e-05\n",
            "Epoch: 50\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 50 \tTraining Loss: 2.4538687385857986e-05 \tValidation Loss: 2.089413010253338e-05\n",
            "Epoch: 51\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 51 \tTraining Loss: 2.379018375601542e-05 \tValidation Loss: 2.2638632799498737e-05\n",
            "Epoch: 52\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 52 \tTraining Loss: 2.4721949052440727e-05 \tValidation Loss: 2.3339070139627438e-05\n",
            "Epoch: 53\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 53 \tTraining Loss: 2.3449851545996757e-05 \tValidation Loss: 2.1915038814768195e-05\n",
            "Epoch: 54\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 54 \tTraining Loss: 2.0811597803711062e-05 \tValidation Loss: 2.0922186195093673e-05\n",
            "\n",
            "Epoch: 55 \tTraining Loss: 2.0953081224838064e-05 \tValidation Loss: 1.8844447367882822e-05\n",
            "Epoch: 56\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 56 \tTraining Loss: 1.9620322038665312e-05 \tValidation Loss: 1.8176664525526576e-05\n",
            "Epoch: 57\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 57 \tTraining Loss: 1.9157333958396015e-05 \tValidation Loss: 1.7597390069568064e-05\n",
            "Epoch: 58\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 58 \tTraining Loss: 1.8965540322015942e-05 \tValidation Loss: 1.7464767552155536e-05\n",
            "Epoch: 59\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 59 \tTraining Loss: 1.8165043355919705e-05 \tValidation Loss: 1.804904059099499e-05\n",
            "Epoch: 60\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 60 \tTraining Loss: 1.856835923616826e-05 \tValidation Loss: 1.9224004972784314e-05\n",
            "\n",
            "Epoch: 61 \tTraining Loss: 1.8509312212700024e-05 \tValidation Loss: 1.6938545741140842e-05\n",
            "Epoch: 62\t100.00% complete. 0.71 seconds elapsed in epoch.\n",
            "Epoch: 62 \tTraining Loss: 1.8035393926159788e-05 \tValidation Loss: 1.7873396245704498e-05\n",
            "Epoch: 63\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 63 \tTraining Loss: 1.737976001297486e-05 \tValidation Loss: 1.6630931895633694e-05\n",
            "Epoch: 64\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 64 \tTraining Loss: 1.7351122601717685e-05 \tValidation Loss: 1.7159708477265667e-05\n",
            "Epoch: 65\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 65 \tTraining Loss: 1.7108928861691515e-05 \tValidation Loss: 1.6253529793175403e-05\n",
            "Epoch: 66\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 66 \tTraining Loss: 1.6555284623286247e-05 \tValidation Loss: 1.6559150026296265e-05\n",
            "Epoch: 67\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 67 \tTraining Loss: 1.6289655276422207e-05 \tValidation Loss: 1.5979474937921623e-05\n",
            "\n",
            "Epoch: 68 \tTraining Loss: 1.7285321973758982e-05 \tValidation Loss: 1.9791423255810514e-05\n",
            "Epoch: 69\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 69 \tTraining Loss: 1.6596642581134802e-05 \tValidation Loss: 1.5316558801714564e-05\n",
            "Epoch: 70\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 70 \tTraining Loss: 1.6498847647502164e-05 \tValidation Loss: 1.6399768355768174e-05\n",
            "Epoch: 71\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 71 \tTraining Loss: 1.6365915497671165e-05 \tValidation Loss: 1.668396726017818e-05\n",
            "Epoch: 72\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 72 \tTraining Loss: 1.948309485063267e-05 \tValidation Loss: 1.850747321441304e-05\n",
            "Epoch: 73\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 73 \tTraining Loss: 1.6497770401555397e-05 \tValidation Loss: 1.644726489757886e-05\n",
            "Epoch: 74\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 74 \tTraining Loss: 1.5889302075164676e-05 \tValidation Loss: 1.5366018033091677e-05\n",
            "Epoch: 75\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 75 \tTraining Loss: 1.515134817964281e-05 \tValidation Loss: 1.5302453903132118e-05\n",
            "Epoch: 76\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 76 \tTraining Loss: 1.537761474739657e-05 \tValidation Loss: 1.4748423382116016e-05\n",
            "Epoch: 77\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 77 \tTraining Loss: 1.6581749959085653e-05 \tValidation Loss: 2.0906944882881362e-05\n",
            "Epoch: 78\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 78 \tTraining Loss: 2.2949099426720448e-05 \tValidation Loss: 1.4900548649166012e-05\n",
            "Epoch: 79\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 79 \tTraining Loss: 1.6745066002638647e-05 \tValidation Loss: 1.4582849871658254e-05\n",
            "Epoch: 80\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 80 \tTraining Loss: 1.4842005031015207e-05 \tValidation Loss: 1.3718292393605225e-05\n",
            "Epoch: 81\t100.00% complete. 0.66 seconds elapsed in epoch.\n",
            "Epoch: 81 \tTraining Loss: 1.4019235903914603e-05 \tValidation Loss: 1.4497643405775307e-05\n",
            "Epoch: 82\t100.00% complete. 0.73 seconds elapsed in epoch.\n",
            "Epoch: 82 \tTraining Loss: 1.6658583717799047e-05 \tValidation Loss: 1.658670953474939e-05\n",
            "Epoch: 83\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 83 \tTraining Loss: 1.5270002020568223e-05 \tValidation Loss: 1.5123261619010009e-05\n",
            "Epoch: 84\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 84 \tTraining Loss: 1.3722073971520229e-05 \tValidation Loss: 1.3023859537497628e-05\n",
            "Epoch: 85\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 85 \tTraining Loss: 1.4911100758278431e-05 \tValidation Loss: 1.3180907899368322e-05\n",
            "\n",
            "Epoch: 86 \tTraining Loss: 1.5428205541765135e-05 \tValidation Loss: 1.3241017313703196e-05\n",
            "Epoch: 87\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 87 \tTraining Loss: 1.605353418199229e-05 \tValidation Loss: 1.2676662208832568e-05\n",
            "Epoch: 88\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 88 \tTraining Loss: 1.4303806690602667e-05 \tValidation Loss: 1.5756085304019507e-05\n",
            "Epoch: 89\t100.00% complete. 0.48 seconds elapsed in epoch.\n",
            "Epoch: 89 \tTraining Loss: 1.563427920498523e-05 \tValidation Loss: 1.3629054137709318e-05\n",
            "Epoch: 90\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 90 \tTraining Loss: 1.9065487726442774e-05 \tValidation Loss: 5.783692540717311e-05\n",
            "Epoch: 91\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 91 \tTraining Loss: 2.8077600846801135e-05 \tValidation Loss: 1.820537363528274e-05\n",
            "Epoch: 92\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 92 \tTraining Loss: 2.5669606354009982e-05 \tValidation Loss: 2.2264103790803347e-05\n",
            "Epoch: 93\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 93 \tTraining Loss: 1.4221137613882698e-05 \tValidation Loss: 1.4963520243327366e-05\n",
            "Epoch: 94\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 94 \tTraining Loss: 1.2514490056976987e-05 \tValidation Loss: 1.218978422912187e-05\n",
            "Epoch: 95\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 95 \tTraining Loss: 1.1892574194563269e-05 \tValidation Loss: 1.1534325949469348e-05\n",
            "Epoch: 96\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 96 \tTraining Loss: 1.199264069226855e-05 \tValidation Loss: 1.3444084288494196e-05\n",
            "Epoch: 97\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 97 \tTraining Loss: 1.2137655176047701e-05 \tValidation Loss: 1.2519046322267968e-05\n",
            "Epoch: 98\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 98 \tTraining Loss: 1.5376659828487187e-05 \tValidation Loss: 1.641773678784375e-05\n",
            "Epoch: 99\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 99 \tTraining Loss: 1.659296690882507e-05 \tValidation Loss: 1.7016121091728564e-05\n",
            "Epoch: 100\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 100 \tTraining Loss: 1.1813579931185814e-05 \tValidation Loss: 1.0762046258605551e-05\n",
            "Epoch: 101\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 101 \tTraining Loss: 1.1617093655836976e-05 \tValidation Loss: 1.1498711046442622e-05\n",
            "Epoch: 102\t100.00% complete. 0.72 seconds elapsed in epoch.\n",
            "Epoch: 102 \tTraining Loss: 1.1981548191720827e-05 \tValidation Loss: 1.2501315723056905e-05\n",
            "Epoch: 103\t100.00% complete. 0.70 seconds elapsed in epoch.\n",
            "Epoch: 103 \tTraining Loss: 1.7018882570280563e-05 \tValidation Loss: 4.9047041102312505e-05\n",
            "\n",
            "Epoch: 104 \tTraining Loss: 4.293614716112238e-05 \tValidation Loss: 2.6714512387115974e-05\n",
            "Epoch: 105\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 105 \tTraining Loss: 3.2065222714865944e-05 \tValidation Loss: 3.8564199712709524e-05\n",
            "Epoch: 106\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 106 \tTraining Loss: 1.649117221960397e-05 \tValidation Loss: 9.965742719941773e-06\n",
            "Epoch: 107\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 107 \tTraining Loss: 1.1037983111034717e-05 \tValidation Loss: 1.0269809081364656e-05\n",
            "Epoch: 108\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 108 \tTraining Loss: 1.483003704076206e-05 \tValidation Loss: 4.365759377833456e-05\n",
            "Epoch: 109\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 109 \tTraining Loss: 4.812317754638368e-05 \tValidation Loss: 0.00011460807581897825\n",
            "Epoch: 110\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 110 \tTraining Loss: 7.04721205693204e-05 \tValidation Loss: 2.7429990950622596e-05\n",
            "Epoch: 111\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 111 \tTraining Loss: 2.3100109905903486e-05 \tValidation Loss: 1.0338590072933584e-05\n",
            "\n",
            "Epoch: 112 \tTraining Loss: 1.0807788435664002e-05 \tValidation Loss: 1.619754584680777e-05\n",
            "Epoch: 113\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 113 \tTraining Loss: 1.2646780356185951e-05 \tValidation Loss: 9.514614703221014e-06\n",
            "Epoch: 114\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 114 \tTraining Loss: 1.1552488002861435e-05 \tValidation Loss: 1.1515164715092396e-05\n",
            "Epoch: 115\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 115 \tTraining Loss: 1.3675167489661058e-05 \tValidation Loss: 1.0214401299890596e-05\n",
            "Epoch: 116\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 116 \tTraining Loss: 1.0954978279187344e-05 \tValidation Loss: 8.990788955998141e-06\n",
            "\n",
            "Epoch: 117 \tTraining Loss: 9.381823777706208e-06 \tValidation Loss: 9.080305517272791e-06\n",
            "Epoch: 118\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 118 \tTraining Loss: 9.612880401416785e-06 \tValidation Loss: 1.7346711501886602e-05\n",
            "Epoch: 119\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 119 \tTraining Loss: 1.4094303171279737e-05 \tValidation Loss: 9.146981028607115e-06\n",
            "Epoch: 120\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 120 \tTraining Loss: 9.403203572825683e-06 \tValidation Loss: 9.36282958718948e-06\n",
            "Epoch: 121\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 121 \tTraining Loss: 9.417032338711175e-06 \tValidation Loss: 8.833889751258539e-06\n",
            "Epoch: 122\t100.00% complete. 0.65 seconds elapsed in epoch.\n",
            "Epoch: 122 \tTraining Loss: 8.89051087445599e-06 \tValidation Loss: 8.688438356330153e-06\n",
            "Epoch: 123\t100.00% complete. 0.74 seconds elapsed in epoch.\n",
            "Epoch: 123 \tTraining Loss: 1.0900601460485228e-05 \tValidation Loss: 8.39105632621795e-06\n",
            "Epoch: 124\t100.00% complete. 0.58 seconds elapsed in epoch.\n",
            "Epoch: 124 \tTraining Loss: 1.2116501819845224e-05 \tValidation Loss: 9.583131031831726e-06\n",
            "Epoch: 125\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 125 \tTraining Loss: 1.0126345412370736e-05 \tValidation Loss: 2.2953860025154427e-05\n",
            "Epoch: 126\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 126 \tTraining Loss: 1.1062519964373982e-05 \tValidation Loss: 9.30499436435639e-06\n",
            "Epoch: 127\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 127 \tTraining Loss: 1.0068276676772964e-05 \tValidation Loss: 8.08449885880691e-06\n",
            "Epoch: 128\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 128 \tTraining Loss: 2.3848237383895645e-05 \tValidation Loss: 6.691509588563349e-05\n",
            "Epoch: 129\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 129 \tTraining Loss: 4.436665252190627e-05 \tValidation Loss: 9.186840543407016e-05\n",
            "Epoch: 130\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 130 \tTraining Loss: 0.00011234493058509543 \tValidation Loss: 7.346335041802377e-05\n",
            "Epoch: 131\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 131 \tTraining Loss: 0.00020898184013478586 \tValidation Loss: 0.000191111299500335\n",
            "Epoch: 132\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 132 \tTraining Loss: 4.294190850689322e-05 \tValidation Loss: 1.0209055290033575e-05\n",
            "Epoch: 133\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 133 \tTraining Loss: 9.828541452508136e-06 \tValidation Loss: 7.506255769840209e-06\n",
            "Epoch: 134\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 134 \tTraining Loss: 1.6646122730890056e-05 \tValidation Loss: 8.627373063063715e-06\n",
            "Epoch: 135\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 135 \tTraining Loss: 1.4786554553817647e-05 \tValidation Loss: 2.434104862913955e-05\n",
            "\n",
            "Epoch: 136 \tTraining Loss: 9.351366669660718e-06 \tValidation Loss: 7.305010967684211e-06\n",
            "Epoch: 137\t100.00% complete. 0.48 seconds elapsed in epoch.\n",
            "Epoch: 137 \tTraining Loss: 9.975677610580331e-06 \tValidation Loss: 8.01352643975406e-06\n",
            "Epoch: 138\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 138 \tTraining Loss: 8.202398425459654e-06 \tValidation Loss: 1.102427586374688e-05\n",
            "Epoch: 139\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 139 \tTraining Loss: 1.2671403182038273e-05 \tValidation Loss: 2.8267053494346328e-05\n",
            "Epoch: 140\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 140 \tTraining Loss: 1.185203243241833e-05 \tValidation Loss: 7.665813882340444e-06\n",
            "\n",
            "Epoch: 141 \tTraining Loss: 1.4138182652661473e-05 \tValidation Loss: 2.9137298042769544e-05\n",
            "Epoch: 142\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 142 \tTraining Loss: 1.4391691845756011e-05 \tValidation Loss: 7.544265827164054e-06\n",
            "Epoch: 143\t100.00% complete. 0.71 seconds elapsed in epoch.\n",
            "Epoch: 143 \tTraining Loss: 2.225462799287925e-05 \tValidation Loss: 2.8542626751004718e-05\n",
            "Epoch: 144\t100.00% complete. 0.70 seconds elapsed in epoch.\n",
            "Epoch: 144 \tTraining Loss: 1.2568720497559601e-05 \tValidation Loss: 1.872179564088583e-05\n",
            "Epoch: 145\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 145 \tTraining Loss: 1.2269209037185647e-05 \tValidation Loss: 6.98043140801019e-06\n",
            "Epoch: 146\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 146 \tTraining Loss: 6.9300248873736964e-06 \tValidation Loss: 9.841034170676721e-06\n",
            "\n",
            "Epoch: 147 \tTraining Loss: 8.366454974546084e-06 \tValidation Loss: 2.2737573090125807e-05\n",
            "Epoch: 148\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 148 \tTraining Loss: 1.1258795464325683e-05 \tValidation Loss: 6.408525223378092e-06\n",
            "Epoch: 149\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 149 \tTraining Loss: 6.629553480605763e-06 \tValidation Loss: 6.292459147516638e-06\n",
            "Epoch: 150\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 150 \tTraining Loss: 9.279361847802647e-06 \tValidation Loss: 8.012848411453888e-06\n",
            "Epoch: 151\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 151 \tTraining Loss: 7.084301058865903e-06 \tValidation Loss: 7.164979024310014e-06\n",
            "Epoch: 152\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 152 \tTraining Loss: 6.8351917737648664e-06 \tValidation Loss: 6.5123792865051655e-06\n",
            "Epoch: 153\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 153 \tTraining Loss: 6.324138010111508e-06 \tValidation Loss: 6.621537295359303e-06\n",
            "Epoch: 154\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 154 \tTraining Loss: 8.300362550370563e-06 \tValidation Loss: 6.1374337292363634e-06\n",
            "Epoch: 155\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 155 \tTraining Loss: 6.901981628794198e-06 \tValidation Loss: 6.357208576446283e-06\n",
            "Epoch: 156\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 156 \tTraining Loss: 7.081126240235689e-06 \tValidation Loss: 9.680798939371016e-06\n",
            "Epoch: 157\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 157 \tTraining Loss: 7.967446183303966e-06 \tValidation Loss: 8.02171120994899e-06\n",
            "Epoch: 158\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 158 \tTraining Loss: 7.282248993255456e-06 \tValidation Loss: 6.4293672039639205e-06\n",
            "Epoch: 159\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 159 \tTraining Loss: 0.00022133079649696205 \tValidation Loss: 0.0018760135862976313\n",
            "Epoch: 160\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 160 \tTraining Loss: 0.0009360636880349679 \tValidation Loss: 0.00045414071064442396\n",
            "Epoch: 161\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 161 \tTraining Loss: 0.00015904232749461598 \tValidation Loss: 7.241561979753897e-05\n",
            "Epoch: 162\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 162 \tTraining Loss: 2.9816165857078482e-05 \tValidation Loss: 1.3006376320845447e-05\n",
            "Epoch: 163\t100.00% complete. 0.65 seconds elapsed in epoch.\n",
            "Epoch: 163 \tTraining Loss: 1.0226358578317255e-05 \tValidation Loss: 7.130197673177463e-06\n",
            "Epoch: 164\t100.00% complete. 0.72 seconds elapsed in epoch.\n",
            "Epoch: 164 \tTraining Loss: 6.556322912527119e-06 \tValidation Loss: 5.75315380046959e-06\n",
            "Epoch: 165\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 165 \tTraining Loss: 7.268398803716991e-06 \tValidation Loss: 9.60570923780324e-06\n",
            "Epoch: 166\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 166 \tTraining Loss: 7.357961749221431e-06 \tValidation Loss: 5.9623712331813294e-06\n",
            "Epoch: 167\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 167 \tTraining Loss: 6.221018616593534e-06 \tValidation Loss: 5.748220701207174e-06\n",
            "Epoch: 168\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 168 \tTraining Loss: 6.309764153734755e-06 \tValidation Loss: 8.127003866320592e-06\n",
            "\n",
            "Epoch: 169 \tTraining Loss: 6.396401785322168e-06 \tValidation Loss: 6.517556130347657e-06\n",
            "Epoch: 170\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 170 \tTraining Loss: 8.791134885339286e-06 \tValidation Loss: 6.726335413986817e-06\n",
            "Epoch: 171\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 171 \tTraining Loss: 7.715816385219417e-06 \tValidation Loss: 8.41507971927058e-06\n",
            "Epoch: 172\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 172 \tTraining Loss: 7.59886393097986e-06 \tValidation Loss: 5.281160611048108e-06\n",
            "Epoch: 173\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 173 \tTraining Loss: 5.941548705676622e-06 \tValidation Loss: 7.44640851735312e-06\n",
            "Epoch: 174\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 174 \tTraining Loss: 5.413211662623023e-06 \tValidation Loss: 5.02437933391775e-06\n",
            "Epoch: 175\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 175 \tTraining Loss: 8.245377001811801e-06 \tValidation Loss: 5.401963562690071e-06\n",
            "\n",
            "Epoch: 176 \tTraining Loss: 6.462489560969213e-06 \tValidation Loss: 8.988481567939743e-06\n",
            "Epoch: 177\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 177 \tTraining Loss: 8.56586863543877e-06 \tValidation Loss: 5.679659579982399e-06\n",
            "Epoch: 178\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 178 \tTraining Loss: 5.31462910657865e-06 \tValidation Loss: 4.802596549779992e-06\n",
            "Epoch: 179\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 179 \tTraining Loss: 5.055557393360586e-06 \tValidation Loss: 4.902424734609667e-06\n",
            "Epoch: 180\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 180 \tTraining Loss: 5.3054774424607685e-06 \tValidation Loss: 4.95089602736698e-06\n",
            "\n",
            "Epoch: 181 \tTraining Loss: 5.0791370161581044e-06 \tValidation Loss: 5.021784772907267e-06\n",
            "Epoch: 182\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 182 \tTraining Loss: 5.249238963895348e-06 \tValidation Loss: 5.295501978253014e-06\n",
            "Epoch: 183\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 183 \tTraining Loss: 4.919042870218012e-06 \tValidation Loss: 5.181830147193978e-06\n",
            "\n",
            "Epoch: 184 \tTraining Loss: 5.248890374787152e-06 \tValidation Loss: 5.661971044901293e-06\n",
            "Epoch: 185\t100.00% complete. 0.74 seconds elapsed in epoch.\n",
            "Epoch: 185 \tTraining Loss: 6.552194918185705e-06 \tValidation Loss: 1.6771132322901394e-05\n",
            "Epoch: 186\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 186 \tTraining Loss: 1.1582739186148197e-05 \tValidation Loss: 4.716329385701101e-06\n",
            "\n",
            "Epoch: 187 \tTraining Loss: 1.0298706418628475e-05 \tValidation Loss: 1.14815911729238e-05\n",
            "Epoch: 188\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 188 \tTraining Loss: 8.777226134447523e-06 \tValidation Loss: 8.093351425486617e-06\n",
            "Epoch: 189\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 189 \tTraining Loss: 9.538802386386022e-06 \tValidation Loss: 7.811617933839443e-06\n",
            "Epoch: 190\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 190 \tTraining Loss: 9.916237003279901e-06 \tValidation Loss: 1.2017329481750494e-05\n",
            "Epoch: 191\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 191 \tTraining Loss: 9.536849019140289e-06 \tValidation Loss: 7.841565775379422e-06\n",
            "\n",
            "Epoch: 192 \tTraining Loss: 6.3348044881826754e-06 \tValidation Loss: 6.685346306767315e-06\n",
            "Epoch: 193\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 193 \tTraining Loss: 6.757513397638428e-06 \tValidation Loss: 4.369986527308356e-06\n",
            "Epoch: 194\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 194 \tTraining Loss: 5.368048505260958e-06 \tValidation Loss: 6.633798648181255e-06\n",
            "Epoch: 195\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 195 \tTraining Loss: 6.402627289187674e-06 \tValidation Loss: 1.4510570053971605e-05\n",
            "Epoch: 196\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 196 \tTraining Loss: 6.013515038224189e-06 \tValidation Loss: 6.160637667562696e-06\n",
            "\n",
            "Epoch: 197 \tTraining Loss: 6.0905057731967345e-06 \tValidation Loss: 4.348681841293001e-06\n",
            "Epoch: 198\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 198 \tTraining Loss: 6.630758763195546e-06 \tValidation Loss: 5.5254088238143595e-06\n",
            "\n",
            "Epoch: 199 \tTraining Loss: 4.9713324743707844e-06 \tValidation Loss: 5.2056861932214815e-06\n",
            "Epoch: 200\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 200 \tTraining Loss: 5.181767417323297e-06 \tValidation Loss: 5.456518238133867e-06\n",
            "Epoch: 201\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 201 \tTraining Loss: 6.784685347661758e-06 \tValidation Loss: 1.2111621344956802e-05\n",
            "Epoch: 202\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 202 \tTraining Loss: 2.015321796180716e-05 \tValidation Loss: 6.765282478227164e-06\n",
            "Epoch: 203\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 203 \tTraining Loss: 1.0208084429703174e-05 \tValidation Loss: 5.121657295603654e-06\n",
            "Epoch: 204\t100.00% complete. 0.66 seconds elapsed in epoch.\n",
            "Epoch: 204 \tTraining Loss: 1.8292925460627885e-05 \tValidation Loss: 8.265484575531445e-05\n",
            "Epoch: 205\t100.00% complete. 0.72 seconds elapsed in epoch.\n",
            "Epoch: 205 \tTraining Loss: 4.510238780615813e-05 \tValidation Loss: 4.9795160066423705e-06\n",
            "\n",
            "Epoch: 206 \tTraining Loss: 1.2034176494226915e-05 \tValidation Loss: 2.7287929697195068e-05\n",
            "Epoch: 207\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 207 \tTraining Loss: 1.786991629160184e-05 \tValidation Loss: 9.694983873487217e-06\n",
            "Epoch: 208\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 208 \tTraining Loss: 1.0036362823484524e-05 \tValidation Loss: 4.517235083767446e-06\n",
            "Epoch: 209\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 209 \tTraining Loss: 6.436005984748287e-06 \tValidation Loss: 7.704237987127271e-06\n",
            "\n",
            "Epoch: 210 \tTraining Loss: 7.090384264706194e-06 \tValidation Loss: 4.110405598112266e-06\n",
            "Epoch: 211\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 211 \tTraining Loss: 2.170758750708046e-05 \tValidation Loss: 4.207988968119025e-05\n",
            "Epoch: 212\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 212 \tTraining Loss: 6.923999704769003e-05 \tValidation Loss: 5.202227384870639e-06\n",
            "Epoch: 213\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 213 \tTraining Loss: 0.0002877482766557983 \tValidation Loss: 0.0006334399222396314\n",
            "Epoch: 214\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 214 \tTraining Loss: 0.0007136736067978847 \tValidation Loss: 0.00047607590386178344\n",
            "\n",
            "Epoch: 215 \tTraining Loss: 0.0001670685288041164 \tValidation Loss: 0.00018192565039498731\n",
            "Epoch: 216\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 216 \tTraining Loss: 3.580930216331682e-05 \tValidation Loss: 6.468882247645524e-06\n",
            "Epoch: 217\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 217 \tTraining Loss: 1.1007578071560905e-05 \tValidation Loss: 1.2000398328382289e-05\n",
            "Epoch: 218\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 218 \tTraining Loss: 5.697866767049062e-06 \tValidation Loss: 3.795489419644582e-06\n",
            "Epoch: 219\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 219 \tTraining Loss: 7.184845344454516e-06 \tValidation Loss: 4.348268248577369e-06\n",
            "Epoch: 220\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 220 \tTraining Loss: 4.469672553063396e-06 \tValidation Loss: 5.973946599624469e-06\n",
            "Epoch: 221\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 221 \tTraining Loss: 1.3847449811995224e-05 \tValidation Loss: 7.014685706963064e-06\n",
            "\n",
            "Epoch: 222 \tTraining Loss: 8.999188025882177e-06 \tValidation Loss: 4.103635433239106e-06\n",
            "Epoch: 223\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 223 \tTraining Loss: 6.862101915632795e-06 \tValidation Loss: 3.7955791185595444e-06\n",
            "Epoch: 224\t100.00% complete. 0.58 seconds elapsed in epoch.\n",
            "Epoch: 224 \tTraining Loss: 4.319973337866638e-06 \tValidation Loss: 4.068081238983723e-06\n",
            "Epoch: 225\t100.00% complete. 0.71 seconds elapsed in epoch.\n",
            "Epoch: 225 \tTraining Loss: 4.251402502733173e-06 \tValidation Loss: 4.09878111895523e-06\n",
            "Epoch: 226\t100.00% complete. 0.67 seconds elapsed in epoch.\n",
            "Epoch: 226 \tTraining Loss: 4.328786682587331e-06 \tValidation Loss: 4.543109525911859e-06\n",
            "Epoch: 227\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 227 \tTraining Loss: 7.315701282095688e-06 \tValidation Loss: 7.543244464613963e-06\n",
            "Epoch: 228\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 228 \tTraining Loss: 5.801696551720346e-06 \tValidation Loss: 4.608802328220918e-06\n",
            "Epoch: 229\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 229 \tTraining Loss: 4.940860056497816e-06 \tValidation Loss: 4.25346547672234e-06\n",
            "Epoch: 230\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 230 \tTraining Loss: 3.931166765546044e-06 \tValidation Loss: 3.543793013704999e-06\n",
            "Epoch: 231\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 231 \tTraining Loss: 4.384193630357913e-06 \tValidation Loss: 3.677473273455689e-06\n",
            "Epoch: 232\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 232 \tTraining Loss: 4.95098112828095e-06 \tValidation Loss: 6.892679948578007e-06\n",
            "Epoch: 233\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 233 \tTraining Loss: 5.176293004499004e-06 \tValidation Loss: 8.808791562842089e-06\n",
            "Epoch: 234\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 234 \tTraining Loss: 1.2990789249064013e-05 \tValidation Loss: 4.024548161396524e-06\n",
            "Epoch: 235\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 235 \tTraining Loss: 1.4140494095550417e-05 \tValidation Loss: 3.707152472998132e-06\n",
            "Epoch: 236\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 236 \tTraining Loss: 5.440065617929375e-06 \tValidation Loss: 4.754878773383098e-06\n",
            "Epoch: 237\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 237 \tTraining Loss: 5.0535996807512775e-06 \tValidation Loss: 5.5038199207047e-06\n",
            "Epoch: 238\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 238 \tTraining Loss: 5.296406293887736e-06 \tValidation Loss: 8.100688546619494e-06\n",
            "Epoch: 239\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 239 \tTraining Loss: 6.327043757260577e-06 \tValidation Loss: 5.838512606715085e-06\n",
            "Epoch: 240\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 240 \tTraining Loss: 9.574816582850568e-06 \tValidation Loss: 1.559830070618773e-05\n",
            "Epoch: 241\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 241 \tTraining Loss: 4.203648710346089e-05 \tValidation Loss: 4.1687884731800295e-05\n",
            "\n",
            "Epoch: 242 \tTraining Loss: 4.228174134368601e-05 \tValidation Loss: 5.775299996457761e-06\n",
            "Epoch: 243\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 243 \tTraining Loss: 1.0220184220896852e-05 \tValidation Loss: 3.5553969155444065e-06\n",
            "Epoch: 244\t100.00% complete. 0.57 seconds elapsed in epoch.\n",
            "Epoch: 244 \tTraining Loss: 7.212043745615422e-06 \tValidation Loss: 1.0151507012778893e-05\n",
            "Epoch: 245\t100.00% complete. 0.74 seconds elapsed in epoch.\n",
            "Epoch: 245 \tTraining Loss: 7.908367453839875e-06 \tValidation Loss: 3.4130584936065134e-06\n",
            "Epoch: 246\t100.00% complete. 0.67 seconds elapsed in epoch.\n",
            "Epoch: 246 \tTraining Loss: 7.027834107652274e-06 \tValidation Loss: 3.275519475209876e-06\n",
            "\n",
            "Epoch: 247 \tTraining Loss: 5.845747877073235e-06 \tValidation Loss: 1.0525260222493671e-05\n",
            "Epoch: 248\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 248 \tTraining Loss: 1.897717498246089e-05 \tValidation Loss: 2.8588610803126357e-05\n",
            "Epoch: 249\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 249 \tTraining Loss: 2.2988540649748757e-05 \tValidation Loss: 5.3227197440719465e-06\n",
            "Epoch: 250\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 250 \tTraining Loss: 4.550513153844804e-06 \tValidation Loss: 6.495290335806203e-06\n",
            "Epoch: 251\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 251 \tTraining Loss: 2.1864028528600305e-05 \tValidation Loss: 8.054886347963475e-05\n",
            "Epoch: 252\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 252 \tTraining Loss: 2.2690291934345118e-05 \tValidation Loss: 1.4804929378442466e-05\n",
            "Epoch: 253\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 253 \tTraining Loss: 1.75072438726905e-05 \tValidation Loss: 3.826674969786836e-06\n",
            "Epoch: 254\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 254 \tTraining Loss: 1.4518462030031918e-05 \tValidation Loss: 1.1264358818152687e-05\n",
            "Epoch: 255\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 255 \tTraining Loss: 8.793708313229823e-06 \tValidation Loss: 4.701244051830145e-06\n",
            "Epoch: 256\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 256 \tTraining Loss: 7.184047174430614e-06 \tValidation Loss: 2.9442197956086602e-05\n",
            "Epoch: 257\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 257 \tTraining Loss: 5.184570226093557e-05 \tValidation Loss: 4.008154428447597e-05\n",
            "Epoch: 258\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 258 \tTraining Loss: 0.0002420043336112738 \tValidation Loss: 8.543529111193493e-05\n",
            "Epoch: 259\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 259 \tTraining Loss: 0.00015338987208855947 \tValidation Loss: 1.3831908745487453e-05\n",
            "Epoch: 260\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 260 \tTraining Loss: 0.000156795837710888 \tValidation Loss: 7.96065287431702e-05\n",
            "\n",
            "Epoch: 261 \tTraining Loss: 3.194043602484776e-05 \tValidation Loss: 7.738862223050091e-06\n",
            "Epoch: 262\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 262 \tTraining Loss: 5.033176408788778e-06 \tValidation Loss: 3.3836479360616067e-06\n",
            "\n",
            "Epoch: 263 \tTraining Loss: 5.634353594056544e-06 \tValidation Loss: 3.965015139328898e-06\n",
            "Epoch: 264\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 264 \tTraining Loss: 8.260420991569441e-06 \tValidation Loss: 5.6175608733610716e-06\n",
            "\n",
            "Epoch: 265 \tTraining Loss: 5.3175643491461715e-06 \tValidation Loss: 3.0747843311473844e-06\n",
            "Epoch: 266\t100.00% complete. 0.73 seconds elapsed in epoch.\n",
            "Epoch: 266 \tTraining Loss: 4.452832311269756e-06 \tValidation Loss: 3.139770683446841e-06\n",
            "Epoch: 267\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 267 \tTraining Loss: 4.370715537839311e-06 \tValidation Loss: 3.1883502060736646e-06\n",
            "Epoch: 268\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 268 \tTraining Loss: 5.634743918866055e-06 \tValidation Loss: 5.554046083489084e-06\n",
            "Epoch: 269\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 269 \tTraining Loss: 3.7581943388431682e-06 \tValidation Loss: 4.04586876356916e-06\n",
            "Epoch: 270\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 270 \tTraining Loss: 3.630860027846615e-06 \tValidation Loss: 3.337255634505709e-06\n",
            "Epoch: 271\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 271 \tTraining Loss: 3.4460581193545495e-06 \tValidation Loss: 5.154804512130795e-06\n",
            "\n",
            "Epoch: 272 \tTraining Loss: 9.368215059011061e-06 \tValidation Loss: 3.6672738588094944e-06\n",
            "Epoch: 273\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 273 \tTraining Loss: 1.2635810713214192e-05 \tValidation Loss: 3.779951475735288e-05\n",
            "\n",
            "Epoch: 274 \tTraining Loss: 1.2854835315718245e-05 \tValidation Loss: 3.124208524241112e-05\n",
            "Epoch: 275\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 275 \tTraining Loss: 1.9495584954003992e-05 \tValidation Loss: 3.450644044278306e-06\n",
            "Epoch: 276\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 276 \tTraining Loss: 4.274294749646086e-06 \tValidation Loss: 4.352307996668969e-06\n",
            "Epoch: 277\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 277 \tTraining Loss: 3.720739123814888e-06 \tValidation Loss: 3.0677110771648586e-06\n",
            "Epoch: 278\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 278 \tTraining Loss: 4.157935450166406e-06 \tValidation Loss: 4.662535502575338e-06\n",
            "Epoch: 279\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 279 \tTraining Loss: 3.619538372529658e-06 \tValidation Loss: 5.930647148488788e-06\n",
            "Epoch: 280\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 280 \tTraining Loss: 6.242903345486815e-06 \tValidation Loss: 7.624222689628368e-06\n",
            "Epoch: 281\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 281 \tTraining Loss: 1.0949695277102162e-05 \tValidation Loss: 1.4075049421080621e-05\n",
            "Epoch: 282\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 282 \tTraining Loss: 1.080086173664717e-05 \tValidation Loss: 4.531434115051525e-06\n",
            "Epoch: 283\t100.00% complete. 0.49 seconds elapsed in epoch.\n",
            "Epoch: 283 \tTraining Loss: 8.546426291407746e-06 \tValidation Loss: 2.323053831787547e-05\n",
            "Epoch: 284\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 284 \tTraining Loss: 2.247429285438961e-05 \tValidation Loss: 6.652923957517487e-06\n",
            "Epoch: 285\t100.00% complete. 0.72 seconds elapsed in epoch.\n",
            "Epoch: 285 \tTraining Loss: 5.28460189899407e-06 \tValidation Loss: 3.5869533121513086e-06\n",
            "Epoch: 286\t100.00% complete. 0.78 seconds elapsed in epoch.\n",
            "Epoch: 286 \tTraining Loss: 7.730385201890991e-06 \tValidation Loss: 4.1522524725223775e-06\n",
            "Epoch: 287\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 287 \tTraining Loss: 1.1051837153293794e-05 \tValidation Loss: 5.673695341101848e-06\n",
            "Epoch: 288\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 288 \tTraining Loss: 0.00010534887378020762 \tValidation Loss: 1.4942570942366729e-05\n",
            "Epoch: 289\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 289 \tTraining Loss: 0.00015946211149437458 \tValidation Loss: 8.75641808306682e-06\n",
            "\n",
            "Epoch: 290 \tTraining Loss: 0.00012258249348128124 \tValidation Loss: 0.0004469154664548114\n",
            "Epoch: 291\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 291 \tTraining Loss: 0.0002760020453125536 \tValidation Loss: 9.007021071738563e-05\n",
            "Epoch: 292\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 292 \tTraining Loss: 5.543911743188801e-05 \tValidation Loss: 7.903695950517431e-05\n",
            "Epoch: 293\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 293 \tTraining Loss: 2.627415906570402e-05 \tValidation Loss: 1.7141776879725512e-05\n",
            "Epoch: 294\t100.00% complete. 0.52 seconds elapsed in epoch.\n",
            "Epoch: 294 \tTraining Loss: 8.603975490789e-06 \tValidation Loss: 3.0374128527910216e-06\n",
            "\n",
            "Epoch: 295 \tTraining Loss: 4.4199297361855215e-06 \tValidation Loss: 3.157501282657904e-06\n",
            "Epoch: 296\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 296 \tTraining Loss: 3.623439650052913e-06 \tValidation Loss: 3.3000123949022964e-06\n",
            "Epoch: 297\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 297 \tTraining Loss: 3.399203150264738e-06 \tValidation Loss: 4.28031512456073e-06\n",
            "Epoch: 298\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 298 \tTraining Loss: 3.904209986810909e-06 \tValidation Loss: 2.8633075999096036e-06\n",
            "Epoch: 299\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 299 \tTraining Loss: 3.235303255324753e-06 \tValidation Loss: 3.069562012569804e-06\n",
            "168.49 total seconds elapsed. 0.56 seconds per epoch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing and training a model with ReLU activations. Note although the network is still name SIREN,\n",
        "# the below model uses only ReLU activations\n",
        "\n",
        "relu_model = Siren(in_features=1, out_features=1, hidden_features=10,\n",
        "                  hidden_layers=10, outermost_linear=True, first_omega_0=1, hidden_omega_0=1,\n",
        "              activ=torch.nn.functional.relu)\n",
        "if train_on_gpu:\n",
        "    relu_model = relu_model.to('cuda')\n",
        "\n",
        "optimizer = torch.optim.RAdam(relu_model.parameters())\n",
        "relu_model, relu_losses = train(relu_model, criteria, optimizer, dataloaders['train'], dataloaders['val'], 300)"
      ],
      "metadata": {
        "id": "5HwMJpulZzJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222cdb4b-031a-4214-a6b3-fc0798d1d6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0 \tTraining Loss: 90.50972938537598 \tValidation Loss: 16.444154739379883\n",
            "Epoch: 1\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 1 \tTraining Loss: 16.36341322792901 \tValidation Loss: 16.137951374053955\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 15.975243091583252 \tValidation Loss: 15.690890789031982\n",
            "Epoch: 3\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 3 \tTraining Loss: 15.461063437991672 \tValidation Loss: 15.12532663345337\n",
            "Epoch: 4\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 4 \tTraining Loss: 14.837086041768393 \tValidation Loss: 14.483208179473877\n",
            "Epoch: 5\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 5 \tTraining Loss: 14.144078625573052 \tValidation Loss: 13.774926662445068\n",
            "Epoch: 6\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 6 \tTraining Loss: 13.398376093970406 \tValidation Loss: 13.019699096679688\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 12.614822228749594 \tValidation Loss: 12.240815162658691\n",
            "Epoch: 8\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 8 \tTraining Loss: 11.812704033321804 \tValidation Loss: 11.452367782592773\n",
            "Epoch: 9\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 9 \tTraining Loss: 11.005010922749838 \tValidation Loss: 10.667058944702148\n",
            "Epoch: 10\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 10 \tTraining Loss: 10.209258768293592 \tValidation Loss: 9.886152744293213\n",
            "Epoch: 11\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 11 \tTraining Loss: 9.422280391057333 \tValidation Loss: 9.129746437072754\n",
            "\n",
            "Epoch: 12 \tTraining Loss: 8.663206153445774 \tValidation Loss: 8.39687466621399\n",
            "\n",
            "Epoch: 13 \tTraining Loss: 7.932444095611572 \tValidation Loss: 7.694746732711792\n",
            "Epoch: 14\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 14 \tTraining Loss: 7.233334647284614 \tValidation Loss: 7.031139850616455\n",
            "Epoch: 15\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 15 \tTraining Loss: 6.578182299931844 \tValidation Loss: 6.398532152175903\n",
            "Epoch: 16\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 16 \tTraining Loss: 5.956875350740221 \tValidation Loss: 5.809942007064819\n",
            "Epoch: 17\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 17 \tTraining Loss: 5.380169206195408 \tValidation Loss: 5.261094808578491\n",
            "Epoch: 18\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 18 \tTraining Loss: 4.8470390107896595 \tValidation Loss: 4.750513315200806\n",
            "Epoch: 19\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 19 \tTraining Loss: 4.353360414505005 \tValidation Loss: 4.283557891845703\n",
            "Epoch: 20\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 20 \tTraining Loss: 3.9041703012254505 \tValidation Loss: 3.855069637298584\n",
            "Epoch: 21\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 21 \tTraining Loss: 3.493028177155389 \tValidation Loss: 3.4686602354049683\n",
            "Epoch: 22\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 22 \tTraining Loss: 3.1258151398764715 \tValidation Loss: 3.115525722503662\n",
            "Epoch: 23\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 23 \tTraining Loss: 2.7910843822691174 \tValidation Loss: 2.803148031234741\n",
            "Epoch: 24\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 24 \tTraining Loss: 2.4958624045054116 \tValidation Loss: 2.523020625114441\n",
            "Epoch: 25\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 25 \tTraining Loss: 2.2353818151685925 \tValidation Loss: 2.271329879760742\n",
            "Epoch: 26\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 26 \tTraining Loss: 2.00229142109553 \tValidation Loss: 2.053070366382599\n",
            "Epoch: 27\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 27 \tTraining Loss: 1.801697724395328 \tValidation Loss: 1.8600469827651978\n",
            "Epoch: 28\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 28 \tTraining Loss: 1.62645908859041 \tValidation Loss: 1.6924187541007996\n",
            "Epoch: 29\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 29 \tTraining Loss: 1.4755629036161635 \tValidation Loss: 1.547677755355835\n",
            "Epoch: 30\t100.00% complete. 0.48 seconds elapsed in epoch.\n",
            "Epoch: 30 \tTraining Loss: 1.3470767935117085 \tValidation Loss: 1.4226601123809814\n",
            "\n",
            "Epoch: 31 \tTraining Loss: 1.2374628517362807 \tValidation Loss: 1.3164780735969543\n",
            "Epoch: 32\t100.00% complete. 0.59 seconds elapsed in epoch.\n",
            "Epoch: 32 \tTraining Loss: 1.1452356113327875 \tValidation Loss: 1.2268595695495605\n",
            "Epoch: 33\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 33 \tTraining Loss: 1.0681893295711942 \tValidation Loss: 1.151724100112915\n",
            "\n",
            "Epoch: 34 \tTraining Loss: 1.0049138598971896 \tValidation Loss: 1.088130235671997\n",
            "Epoch: 35\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 35 \tTraining Loss: 0.9526531596978506 \tValidation Loss: 1.0353977978229523\n",
            "Epoch: 36\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 36 \tTraining Loss: 0.910185244348314 \tValidation Loss: 0.9918134808540344\n",
            "Epoch: 37\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 37 \tTraining Loss: 0.8756977220376333 \tValidation Loss: 0.9564536809921265\n",
            "Epoch: 38\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 38 \tTraining Loss: 0.848428703016705 \tValidation Loss: 0.9274200201034546\n",
            "Epoch: 39\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 39 \tTraining Loss: 0.8265557818942599 \tValidation Loss: 0.9042052030563354\n",
            "Epoch: 40\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 40 \tTraining Loss: 0.8096780644522773 \tValidation Loss: 0.8851454854011536\n",
            "Epoch: 41\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 41 \tTraining Loss: 0.7963849670357175 \tValidation Loss: 0.8699455857276917\n",
            "Epoch: 42\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 42 \tTraining Loss: 0.7862089044517941 \tValidation Loss: 0.8577542006969452\n",
            "Epoch: 43\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 43 \tTraining Loss: 0.7785585787561204 \tValidation Loss: 0.8477816879749298\n",
            "Epoch: 44\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 44 \tTraining Loss: 0.7725229958693186 \tValidation Loss: 0.8402497172355652\n",
            "Epoch: 45\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 45 \tTraining Loss: 0.768349246846305 \tValidation Loss: 0.8338602483272552\n",
            "Epoch: 46\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 46 \tTraining Loss: 0.7649725046422746 \tValidation Loss: 0.8291030824184418\n",
            "\n",
            "Epoch: 47 \tTraining Loss: 0.7625695831245847 \tValidation Loss: 0.8254263997077942\n",
            "Epoch: 48\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 48 \tTraining Loss: 0.7609521283043755 \tValidation Loss: 0.8222666382789612\n",
            "Epoch: 49\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 49 \tTraining Loss: 0.7595953577094607 \tValidation Loss: 0.8200840353965759\n",
            "Epoch: 50\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 50 \tTraining Loss: 0.7587826914257474 \tValidation Loss: 0.8180288076400757\n",
            "Epoch: 51\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 51 \tTraining Loss: 0.7581217520766788 \tValidation Loss: 0.8165750205516815\n",
            "Epoch: 52\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 52 \tTraining Loss: 0.7576871845457289 \tValidation Loss: 0.8154066205024719\n",
            "Epoch: 53\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 53 \tTraining Loss: 0.757410595814387 \tValidation Loss: 0.814303457736969\n",
            "Epoch: 54\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 54 \tTraining Loss: 0.7572156025303735 \tValidation Loss: 0.8134173154830933\n",
            "Epoch: 55\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 55 \tTraining Loss: 0.7571275267336104 \tValidation Loss: 0.8127036392688751\n",
            "Epoch: 56\t100.00% complete. 0.59 seconds elapsed in epoch.\n",
            "Epoch: 56 \tTraining Loss: 0.7569760183493296 \tValidation Loss: 0.8125686943531036\n",
            "Epoch: 57\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 57 \tTraining Loss: 0.7569669187068939 \tValidation Loss: 0.8120494782924652\n",
            "Epoch: 58\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 58 \tTraining Loss: 0.7568958732816908 \tValidation Loss: 0.8116699457168579\n",
            "\n",
            "Epoch: 59 \tTraining Loss: 0.7568907572163476 \tValidation Loss: 0.8113797008991241\n",
            "Epoch: 60\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 60 \tTraining Loss: 0.7568418549166785 \tValidation Loss: 0.8113210499286652\n",
            "Epoch: 61\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 61 \tTraining Loss: 0.7568467524316576 \tValidation Loss: 0.8112209141254425\n",
            "Epoch: 62\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 62 \tTraining Loss: 0.7568314505947961 \tValidation Loss: 0.8111313283443451\n",
            "Epoch: 63\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 63 \tTraining Loss: 0.756833725505405 \tValidation Loss: 0.8109694421291351\n",
            "Epoch: 64\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 64 \tTraining Loss: 0.7568243907557594 \tValidation Loss: 0.8108819425106049\n",
            "Epoch: 65\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 65 \tTraining Loss: 0.7568430834346347 \tValidation Loss: 0.8107891976833344\n",
            "Epoch: 66\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 66 \tTraining Loss: 0.7568218244446648 \tValidation Loss: 0.8108724057674408\n",
            "Epoch: 67\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 67 \tTraining Loss: 0.7568327022923363 \tValidation Loss: 0.810724288225174\n",
            "\n",
            "Epoch: 68 \tTraining Loss: 0.7568287187152438 \tValidation Loss: 0.8106627464294434\n",
            "Epoch: 69\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 69 \tTraining Loss: 0.7568270961443583 \tValidation Loss: 0.8106100559234619\n",
            "Epoch: 70\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 70 \tTraining Loss: 0.7568253113163842 \tValidation Loss: 0.8106400370597839\n",
            "Epoch: 71\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 71 \tTraining Loss: 0.7568213277392917 \tValidation Loss: 0.810773491859436\n",
            "Epoch: 72\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 72 \tTraining Loss: 0.756823781463835 \tValidation Loss: 0.810705304145813\n",
            "Epoch: 73\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 73 \tTraining Loss: 0.7568205131424798 \tValidation Loss: 0.8107664883136749\n",
            "Epoch: 74\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 74 \tTraining Loss: 0.7568660080432892 \tValidation Loss: 0.8108252584934235\n",
            "Epoch: 75\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 75 \tTraining Loss: 0.756849447886149 \tValidation Loss: 0.8109378516674042\n",
            "Epoch: 76\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 76 \tTraining Loss: 0.7568583654032813 \tValidation Loss: 0.8104520738124847\n",
            "\n",
            "Epoch: 77 \tTraining Loss: 0.7568209403091006 \tValidation Loss: 0.8105581104755402\n",
            "Epoch: 78\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 78 \tTraining Loss: 0.7568285995059543 \tValidation Loss: 0.8106723725795746\n",
            "Epoch: 79\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 79 \tTraining Loss: 0.756829708814621 \tValidation Loss: 0.8107071220874786\n",
            "Epoch: 80\t100.00% complete. 0.61 seconds elapsed in epoch.\n",
            "Epoch: 80 \tTraining Loss: 0.756823307938046 \tValidation Loss: 0.8106712698936462\n",
            "Epoch: 81\t100.00% complete. 0.55 seconds elapsed in epoch.\n",
            "Epoch: 81 \tTraining Loss: 0.7568249569998847 \tValidation Loss: 0.8105675578117371\n",
            "Epoch: 82\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 82 \tTraining Loss: 0.756822427113851 \tValidation Loss: 0.8106145858764648\n",
            "Epoch: 83\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 83 \tTraining Loss: 0.756821784708235 \tValidation Loss: 0.8106233775615692\n",
            "Epoch: 84\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 84 \tTraining Loss: 0.7568334837754568 \tValidation Loss: 0.8105956315994263\n",
            "Epoch: 85\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 85 \tTraining Loss: 0.7568448318375481 \tValidation Loss: 0.8105673491954803\n",
            "\n",
            "Epoch: 86 \tTraining Loss: 0.756834457317988 \tValidation Loss: 0.8109000027179718\n",
            "Epoch: 87\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 87 \tTraining Loss: 0.7568318943182627 \tValidation Loss: 0.810722142457962\n",
            "Epoch: 88\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 88 \tTraining Loss: 0.7568255464235941 \tValidation Loss: 0.8106735050678253\n",
            "Epoch: 89\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 89 \tTraining Loss: 0.7568511399957869 \tValidation Loss: 0.8109709918498993\n",
            "Epoch: 90\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 90 \tTraining Loss: 0.7568264173136817 \tValidation Loss: 0.8108547031879425\n",
            "Epoch: 91\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 91 \tTraining Loss: 0.7568190263377296 \tValidation Loss: 0.8107447028160095\n",
            "Epoch: 92\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 92 \tTraining Loss: 0.7568222979704539 \tValidation Loss: 0.8106476366519928\n",
            "Epoch: 93\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 93 \tTraining Loss: 0.7568338579601712 \tValidation Loss: 0.8105409145355225\n",
            "\n",
            "Epoch: 94 \tTraining Loss: 0.7568337851100497 \tValidation Loss: 0.8107351660728455\n",
            "Epoch: 95\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 95 \tTraining Loss: 0.7568632132477231 \tValidation Loss: 0.8107795417308807\n",
            "Epoch: 96\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 96 \tTraining Loss: 0.7568353679445055 \tValidation Loss: 0.8105273246765137\n",
            "Epoch: 97\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 97 \tTraining Loss: 0.7568284173806509 \tValidation Loss: 0.8107429444789886\n",
            "Epoch: 98\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 98 \tTraining Loss: 0.7569138871298896 \tValidation Loss: 0.8110654950141907\n",
            "Epoch: 99\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 99 \tTraining Loss: 0.7569217019610934 \tValidation Loss: 0.8103193044662476\n",
            "Epoch: 100\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 100 \tTraining Loss: 0.756824490096834 \tValidation Loss: 0.8105627000331879\n",
            "Epoch: 101\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 101 \tTraining Loss: 0.7568202084965177 \tValidation Loss: 0.8106145858764648\n",
            "\n",
            "Epoch: 102 \tTraining Loss: 0.7568372289339701 \tValidation Loss: 0.8105127811431885\n",
            "Epoch: 103\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 103 \tTraining Loss: 0.75685296787156 \tValidation Loss: 0.8109743595123291\n",
            "Epoch: 104\t100.00% complete. 0.59 seconds elapsed in epoch.\n",
            "Epoch: 104 \tTraining Loss: 0.7568407588534884 \tValidation Loss: 0.8105911314487457\n",
            "\n",
            "Epoch: 105 \tTraining Loss: 0.7568395833174387 \tValidation Loss: 0.8107917606830597\n",
            "Epoch: 106\t100.00% complete. 0.46 seconds elapsed in epoch.\n",
            "Epoch: 106 \tTraining Loss: 0.756828698847029 \tValidation Loss: 0.8108768165111542\n",
            "Epoch: 107\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 107 \tTraining Loss: 0.7568206058608161 \tValidation Loss: 0.8105862140655518\n",
            "Epoch: 108\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 108 \tTraining Loss: 0.7568699253929986 \tValidation Loss: 0.8102799952030182\n",
            "Epoch: 109\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 109 \tTraining Loss: 0.7568619516160753 \tValidation Loss: 0.8108557760715485\n",
            "\n",
            "Epoch: 110 \tTraining Loss: 0.7568920254707336 \tValidation Loss: 0.8104243278503418\n",
            "Epoch: 111\t100.00% complete. 0.47 seconds elapsed in epoch.\n",
            "Epoch: 111 \tTraining Loss: 0.7568868464893765 \tValidation Loss: 0.8103229105472565\n",
            "Epoch: 112\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 112 \tTraining Loss: 0.7568501498964098 \tValidation Loss: 0.810662180185318\n",
            "Epoch: 113\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 113 \tTraining Loss: 0.756843176152971 \tValidation Loss: 0.8106870949268341\n",
            "Epoch: 114\t100.00% complete. 0.46 seconds elapsed in epoch.\n",
            "Epoch: 114 \tTraining Loss: 0.7568389144208696 \tValidation Loss: 0.8105818927288055\n",
            "\n",
            "Epoch: 115 \tTraining Loss: 0.7568222416771783 \tValidation Loss: 0.8108959197998047\n",
            "Epoch: 116\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 116 \tTraining Loss: 0.7568279571003385 \tValidation Loss: 0.8109186887741089\n",
            "Epoch: 117\t100.00% complete. 0.47 seconds elapsed in epoch.\n",
            "Epoch: 117 \tTraining Loss: 0.7568496829933591 \tValidation Loss: 0.8106546700000763\n",
            "Epoch: 118\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 118 \tTraining Loss: 0.7568425569269392 \tValidation Loss: 0.8108746409416199\n",
            "Epoch: 119\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 119 \tTraining Loss: 0.7568441596296098 \tValidation Loss: 0.8106440603733063\n",
            "Epoch: 120\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 120 \tTraining Loss: 0.7568538619412316 \tValidation Loss: 0.8105016946792603\n",
            "Epoch: 121\t100.00% complete. 0.46 seconds elapsed in epoch.\n",
            "Epoch: 121 \tTraining Loss: 0.7568449742264218 \tValidation Loss: 0.8106188178062439\n",
            "Epoch: 122\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 122 \tTraining Loss: 0.7568784356117249 \tValidation Loss: 0.8109098672866821\n",
            "Epoch: 123\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 123 \tTraining Loss: 0.7568696969085269 \tValidation Loss: 0.8104202151298523\n",
            "Epoch: 124\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 124 \tTraining Loss: 0.756914883852005 \tValidation Loss: 0.8110060393810272\n",
            "Epoch: 125\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 125 \tTraining Loss: 0.7568514148394266 \tValidation Loss: 0.8104106485843658\n",
            "Epoch: 126\t100.00% complete. 0.50 seconds elapsed in epoch.\n",
            "Epoch: 126 \tTraining Loss: 0.7568857669830322 \tValidation Loss: 0.8102115094661713\n",
            "\n",
            "Epoch: 127 \tTraining Loss: 0.7568155692683326 \tValidation Loss: 0.8105627596378326\n",
            "Epoch: 128\t100.00% complete. 0.63 seconds elapsed in epoch.\n",
            "Epoch: 128 \tTraining Loss: 0.7568428185251024 \tValidation Loss: 0.8104968667030334\n",
            "Epoch: 129\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 129 \tTraining Loss: 0.7568608423074087 \tValidation Loss: 0.8111929297447205\n",
            "Epoch: 130\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 130 \tTraining Loss: 0.7568917142020332 \tValidation Loss: 0.8105991780757904\n",
            "Epoch: 131\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 131 \tTraining Loss: 0.7568328976631165 \tValidation Loss: 0.8107806444168091\n",
            "Epoch: 132\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 132 \tTraining Loss: 0.756843196021186 \tValidation Loss: 0.8105929493904114\n",
            "\n",
            "Epoch: 133 \tTraining Loss: 0.756867809428109 \tValidation Loss: 0.8106099665164948\n",
            "Epoch: 134\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 134 \tTraining Loss: 0.7568450702561272 \tValidation Loss: 0.8106929659843445\n",
            "Epoch: 135\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 135 \tTraining Loss: 0.7568545043468475 \tValidation Loss: 0.8106680512428284\n",
            "Epoch: 136\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 136 \tTraining Loss: 0.7568320532639822 \tValidation Loss: 0.8109025955200195\n",
            "Epoch: 137\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 137 \tTraining Loss: 0.7568621337413788 \tValidation Loss: 0.8107405602931976\n",
            "Epoch: 138\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 138 \tTraining Loss: 0.756846136516995 \tValidation Loss: 0.8106171190738678\n",
            "Epoch: 139\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 139 \tTraining Loss: 0.7568455272250705 \tValidation Loss: 0.8107729256153107\n",
            "Epoch: 140\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 140 \tTraining Loss: 0.7568621966573927 \tValidation Loss: 0.8109292089939117\n",
            "Epoch: 141\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 141 \tTraining Loss: 0.7568418747848935 \tValidation Loss: 0.8105334341526031\n",
            "\n",
            "Epoch: 142 \tTraining Loss: 0.756834884484609 \tValidation Loss: 0.8106087148189545\n",
            "Epoch: 143\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 143 \tTraining Loss: 0.7569047742419772 \tValidation Loss: 0.8101877570152283\n",
            "Epoch: 144\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 144 \tTraining Loss: 0.7569132679038577 \tValidation Loss: 0.8111721873283386\n",
            "Epoch: 145\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 145 \tTraining Loss: 0.7568935983710818 \tValidation Loss: 0.8104182183742523\n",
            "Epoch: 146\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 146 \tTraining Loss: 0.7568560110198127 \tValidation Loss: 0.8107657134532928\n",
            "Epoch: 147\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 147 \tTraining Loss: 0.7568508717748854 \tValidation Loss: 0.810673713684082\n",
            "Epoch: 148\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 148 \tTraining Loss: 0.7568781342771318 \tValidation Loss: 0.8107887208461761\n",
            "Epoch: 149\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 149 \tTraining Loss: 0.7568699320157369 \tValidation Loss: 0.810417503118515\n",
            "Epoch: 150\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 150 \tTraining Loss: 0.7568789025147756 \tValidation Loss: 0.8101997077465057\n",
            "\n",
            "Epoch: 151 \tTraining Loss: 0.7569594648149278 \tValidation Loss: 0.8109609484672546\n",
            "\n",
            "Epoch: 152 \tTraining Loss: 0.7568370732996199 \tValidation Loss: 0.810724675655365\n",
            "Epoch: 153\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 153 \tTraining Loss: 0.7569486730628543 \tValidation Loss: 0.8100993037223816\n",
            "Epoch: 154\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 154 \tTraining Loss: 0.7568342188994089 \tValidation Loss: 0.8105530738830566\n",
            "Epoch: 155\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 155 \tTraining Loss: 0.7568882240189446 \tValidation Loss: 0.8114379048347473\n",
            "Epoch: 156\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 156 \tTraining Loss: 0.7569059994485643 \tValidation Loss: 0.8105885982513428\n",
            "Epoch: 157\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 157 \tTraining Loss: 0.7568365103668637 \tValidation Loss: 0.8108416795730591\n",
            "\n",
            "Epoch: 158 \tTraining Loss: 0.7569056815571256 \tValidation Loss: 0.8111623823642731\n",
            "Epoch: 159\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 159 \tTraining Loss: 0.7568538453843858 \tValidation Loss: 0.8109873235225677\n",
            "Epoch: 160\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 160 \tTraining Loss: 0.7568295001983643 \tValidation Loss: 0.8106837272644043\n",
            "Epoch: 161\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 161 \tTraining Loss: 0.7568721274534861 \tValidation Loss: 0.8101464509963989\n",
            "Epoch: 162\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 162 \tTraining Loss: 0.7570074432426028 \tValidation Loss: 0.8110929429531097\n",
            "Epoch: 163\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 163 \tTraining Loss: 0.7568332188659244 \tValidation Loss: 0.8103204965591431\n",
            "Epoch: 164\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 164 \tTraining Loss: 0.7569095426135592 \tValidation Loss: 0.8103420436382294\n",
            "Epoch: 165\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 165 \tTraining Loss: 0.7568576335906982 \tValidation Loss: 0.8105384707450867\n",
            "Epoch: 166\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 166 \tTraining Loss: 0.756879856189092 \tValidation Loss: 0.811178058385849\n",
            "\n",
            "Epoch: 167 \tTraining Loss: 0.7568361527389951 \tValidation Loss: 0.8107553720474243\n",
            "Epoch: 168\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 168 \tTraining Loss: 0.7568672630521986 \tValidation Loss: 0.8102752268314362\n",
            "Epoch: 169\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 169 \tTraining Loss: 0.7568387157387204 \tValidation Loss: 0.8103180825710297\n",
            "Epoch: 170\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 170 \tTraining Loss: 0.7568361792299483 \tValidation Loss: 0.8107828199863434\n",
            "Epoch: 171\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 171 \tTraining Loss: 0.7568677597575717 \tValidation Loss: 0.81053227186203\n",
            "Epoch: 172\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 172 \tTraining Loss: 0.7570830318662856 \tValidation Loss: 0.8115780651569366\n",
            "Epoch: 173\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 173 \tTraining Loss: 0.7568527393870883 \tValidation Loss: 0.8101492822170258\n",
            "Epoch: 174\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 174 \tTraining Loss: 0.7568659087022146 \tValidation Loss: 0.8105537593364716\n",
            "Epoch: 175\t100.00% complete. 0.58 seconds elapsed in epoch.\n",
            "Epoch: 175 \tTraining Loss: 0.7568658126725091 \tValidation Loss: 0.8102862536907196\n",
            "Epoch: 176\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 176 \tTraining Loss: 0.7568910585509406 \tValidation Loss: 0.8102182447910309\n",
            "Epoch: 177\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 177 \tTraining Loss: 0.7568269636895921 \tValidation Loss: 0.8111202120780945\n",
            "Epoch: 178\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 178 \tTraining Loss: 0.7569682200749716 \tValidation Loss: 0.810407966375351\n",
            "Epoch: 179\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 179 \tTraining Loss: 0.7568626734945509 \tValidation Loss: 0.8110333383083344\n",
            "Epoch: 180\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 180 \tTraining Loss: 0.7568891081545088 \tValidation Loss: 0.8111645877361298\n",
            "\n",
            "Epoch: 181 \tTraining Loss: 0.7568580773141649 \tValidation Loss: 0.8106165826320648\n",
            "Epoch: 182\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 182 \tTraining Loss: 0.7568577859136794 \tValidation Loss: 0.810648113489151\n",
            "Epoch: 183\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 183 \tTraining Loss: 0.7569476068019867 \tValidation Loss: 0.811115026473999\n",
            "Epoch: 184\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 184 \tTraining Loss: 0.7569013006157346 \tValidation Loss: 0.8104127943515778\n",
            "Epoch: 185\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 185 \tTraining Loss: 0.7569483949078454 \tValidation Loss: 0.8100703060626984\n",
            "Epoch: 186\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 186 \tTraining Loss: 0.7568763825628493 \tValidation Loss: 0.8110138177871704\n",
            "Epoch: 187\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 187 \tTraining Loss: 0.7568448318375481 \tValidation Loss: 0.810931533575058\n",
            "Epoch: 188\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 188 \tTraining Loss: 0.7568573885493808 \tValidation Loss: 0.8104003667831421\n",
            "Epoch: 189\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 189 \tTraining Loss: 0.7569083174069723 \tValidation Loss: 0.8110232353210449\n",
            "Epoch: 190\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 190 \tTraining Loss: 0.7568920718299018 \tValidation Loss: 0.8104898631572723\n",
            "\n",
            "Epoch: 191 \tTraining Loss: 0.756863233115938 \tValidation Loss: 0.8109637200832367\n",
            "Epoch: 192\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 192 \tTraining Loss: 0.7568545771969689 \tValidation Loss: 0.8105194270610809\n",
            "Epoch: 193\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 193 \tTraining Loss: 0.7569562163617876 \tValidation Loss: 0.8102347552776337\n",
            "Epoch: 194\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 194 \tTraining Loss: 0.7568190693855286 \tValidation Loss: 0.8111286759376526\n",
            "Epoch: 195\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 195 \tTraining Loss: 0.7569494214322832 \tValidation Loss: 0.8112581968307495\n",
            "Epoch: 196\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 196 \tTraining Loss: 0.7568657133314345 \tValidation Loss: 0.810604065656662\n",
            "Epoch: 197\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 197 \tTraining Loss: 0.7569237086508009 \tValidation Loss: 0.8100806474685669\n",
            "Epoch: 198\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 198 \tTraining Loss: 0.7569466067685021 \tValidation Loss: 0.8107605576515198\n",
            "Epoch: 199\t100.00% complete. 0.53 seconds elapsed in epoch.\n",
            "Epoch: 199 \tTraining Loss: 0.7570922805203332 \tValidation Loss: 0.8117182552814484\n",
            "Epoch: 200\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 200 \tTraining Loss: 0.7568598555194007 \tValidation Loss: 0.8104658424854279\n",
            "\n",
            "Epoch: 201 \tTraining Loss: 0.7569104863537682 \tValidation Loss: 0.8107672333717346\n",
            "Epoch: 202\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 202 \tTraining Loss: 0.7568542460600535 \tValidation Loss: 0.8103738129138947\n",
            "Epoch: 203\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 203 \tTraining Loss: 0.7569171554512448 \tValidation Loss: 0.810306191444397\n",
            "Epoch: 204\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 204 \tTraining Loss: 0.7568599449263679 \tValidation Loss: 0.8106555044651031\n",
            "Epoch: 205\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 205 \tTraining Loss: 0.7568965587351058 \tValidation Loss: 0.8110861778259277\n",
            "Epoch: 206\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 206 \tTraining Loss: 0.7569049530559115 \tValidation Loss: 0.8106287121772766\n",
            "Epoch: 207\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 207 \tTraining Loss: 0.7569874491956499 \tValidation Loss: 0.8106831014156342\n",
            "Epoch: 208\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 208 \tTraining Loss: 0.7568913830651177 \tValidation Loss: 0.8112296462059021\n",
            "Epoch: 209\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 209 \tTraining Loss: 0.7569258974658118 \tValidation Loss: 0.8105385601520538\n",
            "\n",
            "Epoch: 210 \tTraining Loss: 0.7568652298715379 \tValidation Loss: 0.8109384775161743\n",
            "Epoch: 211\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 211 \tTraining Loss: 0.7568714320659637 \tValidation Loss: 0.8111414313316345\n",
            "Epoch: 212\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 212 \tTraining Loss: 0.7568512691391839 \tValidation Loss: 0.8104918003082275\n",
            "Epoch: 213\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 213 \tTraining Loss: 0.7569063636991713 \tValidation Loss: 0.8101846277713776\n",
            "Epoch: 214\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 214 \tTraining Loss: 0.7569137712319692 \tValidation Loss: 0.8102996051311493\n",
            "Epoch: 215\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 215 \tTraining Loss: 0.7568503287103441 \tValidation Loss: 0.810695469379425\n",
            "Epoch: 216\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 216 \tTraining Loss: 0.7570954064528147 \tValidation Loss: 0.8112565875053406\n",
            "Epoch: 217\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 217 \tTraining Loss: 0.7572020557191637 \tValidation Loss: 0.8095706403255463\n",
            "Epoch: 218\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 218 \tTraining Loss: 0.7570264074537489 \tValidation Loss: 0.8112331628799438\n",
            "\n",
            "Epoch: 219 \tTraining Loss: 0.7568995257218679 \tValidation Loss: 0.8102249205112457\n",
            "Epoch: 220\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 220 \tTraining Loss: 0.7569731540150113 \tValidation Loss: 0.8108762204647064\n",
            "Epoch: 221\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 221 \tTraining Loss: 0.7569960157076517 \tValidation Loss: 0.8098452985286713\n",
            "Epoch: 222\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 222 \tTraining Loss: 0.7568739189041985 \tValidation Loss: 0.8106614947319031\n",
            "Epoch: 223\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 223 \tTraining Loss: 0.7570248014397092 \tValidation Loss: 0.8101569712162018\n",
            "Epoch: 224\t100.00% complete. 0.62 seconds elapsed in epoch.\n",
            "Epoch: 224 \tTraining Loss: 0.7568600144651201 \tValidation Loss: 0.810917466878891\n",
            "Epoch: 225\t100.00% complete. 0.59 seconds elapsed in epoch.\n",
            "Epoch: 225 \tTraining Loss: 0.7568782567977905 \tValidation Loss: 0.811229795217514\n",
            "Epoch: 226\t100.00% complete. 0.47 seconds elapsed in epoch.\n",
            "Epoch: 226 \tTraining Loss: 0.7568446165985532 \tValidation Loss: 0.8100009560585022\n",
            "Epoch: 227\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 227 \tTraining Loss: 0.7568915850586362 \tValidation Loss: 0.8110160529613495\n",
            "Epoch: 228\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 228 \tTraining Loss: 0.7570459180408053 \tValidation Loss: 0.8111190497875214\n",
            "Epoch: 229\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 229 \tTraining Loss: 0.7569047278828092 \tValidation Loss: 0.8102227449417114\n",
            "Epoch: 230\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 230 \tTraining Loss: 0.7568913102149963 \tValidation Loss: 0.810882568359375\n",
            "\n",
            "Epoch: 231 \tTraining Loss: 0.7569672829575009 \tValidation Loss: 0.811031311750412\n",
            "Epoch: 232\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 232 \tTraining Loss: 0.7568546169333987 \tValidation Loss: 0.8108547329902649\n",
            "Epoch: 233\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 233 \tTraining Loss: 0.7568643457359738 \tValidation Loss: 0.8108260929584503\n",
            "Epoch: 234\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 234 \tTraining Loss: 0.7568961415025923 \tValidation Loss: 0.8104749023914337\n",
            "Epoch: 235\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 235 \tTraining Loss: 0.7568584647443559 \tValidation Loss: 0.8102717399597168\n",
            "Epoch: 236\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 236 \tTraining Loss: 0.7571050822734833 \tValidation Loss: 0.8096734881401062\n",
            "Epoch: 237\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 237 \tTraining Loss: 0.7570932474401262 \tValidation Loss: 0.8112148344516754\n",
            "Epoch: 238\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 238 \tTraining Loss: 0.7568783197138045 \tValidation Loss: 0.8105461299419403\n",
            "Epoch: 239\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 239 \tTraining Loss: 0.7569392025470734 \tValidation Loss: 0.8100894391536713\n",
            "\n",
            "Epoch: 240 \tTraining Loss: 0.7574696077240838 \tValidation Loss: 0.8122473061084747\n",
            "Epoch: 241\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 241 \tTraining Loss: 0.7571152879132165 \tValidation Loss: 0.8090952336788177\n",
            "Epoch: 242\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 242 \tTraining Loss: 0.7569857140382131 \tValidation Loss: 0.8110783994197845\n",
            "Epoch: 243\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 243 \tTraining Loss: 0.7568764620357089 \tValidation Loss: 0.8105340600013733\n",
            "Epoch: 244\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 244 \tTraining Loss: 0.7571262485451169 \tValidation Loss: 0.8101509809494019\n",
            "Epoch: 245\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 245 \tTraining Loss: 0.7571412689156003 \tValidation Loss: 0.810951292514801\n",
            "Epoch: 246\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 246 \tTraining Loss: 0.757129493686888 \tValidation Loss: 0.8088972866535187\n",
            "Epoch: 247\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 247 \tTraining Loss: 0.7569826179080539 \tValidation Loss: 0.8114140927791595\n",
            "Epoch: 248\t100.00% complete. 0.58 seconds elapsed in epoch.\n",
            "Epoch: 248 \tTraining Loss: 0.7570479677783118 \tValidation Loss: 0.8100095689296722\n",
            "Epoch: 249\t100.00% complete. 0.60 seconds elapsed in epoch.\n",
            "Epoch: 249 \tTraining Loss: 0.7568871676921844 \tValidation Loss: 0.8108161985874176\n",
            "Epoch: 250\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 250 \tTraining Loss: 0.7569139434231652 \tValidation Loss: 0.8108091354370117\n",
            "Epoch: 251\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 251 \tTraining Loss: 0.75688346558147 \tValidation Loss: 0.8112227618694305\n",
            "Epoch: 252\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 252 \tTraining Loss: 0.7568985323111216 \tValidation Loss: 0.8107129335403442\n",
            "\n",
            "Epoch: 253 \tTraining Loss: 0.75725257396698 \tValidation Loss: 0.8112694621086121\n",
            "Epoch: 254\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 254 \tTraining Loss: 0.7571357587973276 \tValidation Loss: 0.8087394535541534\n",
            "Epoch: 255\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 255 \tTraining Loss: 0.7569008138444688 \tValidation Loss: 0.8104356825351715\n",
            "Epoch: 256\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 256 \tTraining Loss: 0.7569231457180448 \tValidation Loss: 0.8120636641979218\n",
            "Epoch: 257\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 257 \tTraining Loss: 0.7569463915295072 \tValidation Loss: 0.8111304044723511\n",
            "Epoch: 258\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 258 \tTraining Loss: 0.756913403669993 \tValidation Loss: 0.8101369440555573\n",
            "Epoch: 259\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 259 \tTraining Loss: 0.7568771143754324 \tValidation Loss: 0.8106300532817841\n",
            "Epoch: 260\t100.00% complete. 0.45 seconds elapsed in epoch.\n",
            "Epoch: 260 \tTraining Loss: 0.7572039796246423 \tValidation Loss: 0.810937762260437\n",
            "\n",
            "Epoch: 261 \tTraining Loss: 0.7571610709031423 \tValidation Loss: 0.809605062007904\n",
            "Epoch: 262\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 262 \tTraining Loss: 0.756822986735238 \tValidation Loss: 0.8120347261428833\n",
            "Epoch: 263\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 263 \tTraining Loss: 0.7570420073138343 \tValidation Loss: 0.8114208579063416\n",
            "Epoch: 264\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 264 \tTraining Loss: 0.7571141686704423 \tValidation Loss: 0.8098111152648926\n",
            "Epoch: 265\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 265 \tTraining Loss: 0.7570881942907969 \tValidation Loss: 0.8119238018989563\n",
            "Epoch: 266\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 266 \tTraining Loss: 0.7571786807643043 \tValidation Loss: 0.8109656274318695\n",
            "Epoch: 267\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 267 \tTraining Loss: 0.7568842172622681 \tValidation Loss: 0.8098735511302948\n",
            "Epoch: 268\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 268 \tTraining Loss: 0.7571484545866648 \tValidation Loss: 0.8095028698444366\n",
            "Epoch: 269\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 269 \tTraining Loss: 0.7570968568325043 \tValidation Loss: 0.8119068145751953\n",
            "\n",
            "Epoch: 270 \tTraining Loss: 0.7569081054793464 \tValidation Loss: 0.8098785877227783\n",
            "Epoch: 271\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 271 \tTraining Loss: 0.7570007145404816 \tValidation Loss: 0.8104621767997742\n",
            "Epoch: 272\t100.00% complete. 0.56 seconds elapsed in epoch.\n",
            "Epoch: 272 \tTraining Loss: 0.756857673327128 \tValidation Loss: 0.8110708594322205\n",
            "Epoch: 273\t100.00% complete. 0.62 seconds elapsed in epoch.\n",
            "Epoch: 273 \tTraining Loss: 0.7570101353857253 \tValidation Loss: 0.8104024529457092\n",
            "Epoch: 274\t100.00% complete. 0.54 seconds elapsed in epoch.\n",
            "Epoch: 274 \tTraining Loss: 0.7568826973438263 \tValidation Loss: 0.8103685975074768\n",
            "Epoch: 275\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 275 \tTraining Loss: 0.756978303194046 \tValidation Loss: 0.8103938698768616\n",
            "Epoch: 276\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 276 \tTraining Loss: 0.7569634649488661 \tValidation Loss: 0.8116466999053955\n",
            "Epoch: 277\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 277 \tTraining Loss: 0.7570568025112152 \tValidation Loss: 0.8100585639476776\n",
            "Epoch: 278\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 278 \tTraining Loss: 0.7568860616948869 \tValidation Loss: 0.8110332489013672\n",
            "Epoch: 279\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 279 \tTraining Loss: 0.7569080789883932 \tValidation Loss: 0.8119761943817139\n",
            "\n",
            "Epoch: 280 \tTraining Loss: 0.7568501565191481 \tValidation Loss: 0.8101434111595154\n",
            "Epoch: 281\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 281 \tTraining Loss: 0.7569112380345663 \tValidation Loss: 0.8099773526191711\n",
            "Epoch: 282\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 282 \tTraining Loss: 0.7570208774672614 \tValidation Loss: 0.8117606043815613\n",
            "Epoch: 283\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 283 \tTraining Loss: 0.7569201588630676 \tValidation Loss: 0.8108878433704376\n",
            "Epoch: 284\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 284 \tTraining Loss: 0.7568758030732473 \tValidation Loss: 0.810848593711853\n",
            "Epoch: 285\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 285 \tTraining Loss: 0.7570628126462301 \tValidation Loss: 0.8110231757164001\n",
            "Epoch: 286\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 286 \tTraining Loss: 0.7570996118916405 \tValidation Loss: 0.8115478157997131\n",
            "Epoch: 287\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 287 \tTraining Loss: 0.7570023337999979 \tValidation Loss: 0.80972820520401\n",
            "\n",
            "Epoch: 288 \tTraining Loss: 0.7571122977468703 \tValidation Loss: 0.8098635077476501\n",
            "Epoch: 289\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 289 \tTraining Loss: 0.756843109925588 \tValidation Loss: 0.8111196756362915\n",
            "Epoch: 290\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 290 \tTraining Loss: 0.7572246458795335 \tValidation Loss: 0.8123505711555481\n",
            "Epoch: 291\t100.00% complete. 0.44 seconds elapsed in epoch.\n",
            "Epoch: 291 \tTraining Loss: 0.7569928467273712 \tValidation Loss: 0.810267299413681\n",
            "Epoch: 292\t100.00% complete. 0.41 seconds elapsed in epoch.\n",
            "Epoch: 292 \tTraining Loss: 0.7568951381577386 \tValidation Loss: 0.8109853267669678\n",
            "Epoch: 293\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 293 \tTraining Loss: 0.7569347620010376 \tValidation Loss: 0.8104453384876251\n",
            "Epoch: 294\t100.00% complete. 0.42 seconds elapsed in epoch.\n",
            "Epoch: 294 \tTraining Loss: 0.7570176985528734 \tValidation Loss: 0.8115558624267578\n",
            "Epoch: 295\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 295 \tTraining Loss: 0.757127884361479 \tValidation Loss: 0.810208261013031\n",
            "Epoch: 296\t100.00% complete. 0.51 seconds elapsed in epoch.\n",
            "Epoch: 296 \tTraining Loss: 0.7571268677711487 \tValidation Loss: 0.8103361427783966\n",
            "\n",
            "Epoch: 297 \tTraining Loss: 0.757160892089208 \tValidation Loss: 0.8115683197975159\n",
            "Epoch: 298\t100.00% complete. 0.59 seconds elapsed in epoch.\n",
            "Epoch: 298 \tTraining Loss: 0.7572237021393247 \tValidation Loss: 0.8096647262573242\n",
            "Epoch: 299\t100.00% complete. 0.43 seconds elapsed in epoch.\n",
            "Epoch: 299 \tTraining Loss: 0.7571526169776917 \tValidation Loss: 0.8107403516769409\n",
            "142.47 total seconds elapsed. 0.48 seconds per epoch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot losses\n",
        "EPOCHS = 300\n",
        "plt.scatter(np.arange(EPOCHS), losses, label = 'sine', s = 2)\n",
        "plt.scatter(np.arange(EPOCHS), tanh_losses, label = 'tanh', s = 2)\n",
        "plt.scatter(np.arange(EPOCHS), relu_losses, label = 'relu', s = 2)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss curves')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JMMFXKPpw7Bp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "fe8fa009-c662-48ce-c735-141336209b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABF7UlEQVR4nO3deXhU5f3//9ckQxICWSBAFhMIyB4gKkqKIiIgaykBq4BQARd+slgpxQUXFpeitLbVQrG2VWxxQz4SRBENiFAWQYQIREWIhBBJCASzYpbJnN8f+WZkTAJJSGYmOc/Hdc3lmXPOzLzP7cR5ee77nNtiGIYhAAAAE/FydwEAAACuRgACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACUGurVq2SxWLRvn373F0KANQJAQgAAJgOAQgA6shut6uoqMjdZQCoAwIQgAZz4MABjRw5UoGBgWrZsqWGDBmizz77zGmf0tJSLVmyRF26dJGfn59CQkI0YMAAJSYmOvbJzMzU9OnTFRkZKV9fX4WHh2vs2LFKTU29ZA3ffPONbr/9drVt21bNmzdXt27d9Nhjjzm2T5s2TdHR0ZVet3jxYlksFqd1FotFc+bM0euvv66YmBj5+vpqw4YNat26taZPn17pPfLy8uTn56f58+c71hUXF2vRokXq3LmzfH19FRUVpYceekjFxcVOr01MTNSAAQMUHBysli1bqlu3bnr00UcvebwAasbq7gIANE3Jycm68cYbFRgYqIceekjNmjXTP/7xDw0aNEjbtm1TXFycpPKgsXTpUt1zzz3q16+f8vLytG/fPu3fv1+33HKLJOnWW29VcnKy7r//fkVHRysrK0uJiYlKS0urMrxUOHjwoG688UY1a9ZMM2bMUHR0tFJSUrRhwwY988wzdTquTz75RGvWrNGcOXPUpk0bdenSRePGjdO7776rf/zjH/Lx8XHsm5CQoOLiYk2cOFFS+RmjX/3qV9qxY4dmzJihHj166NChQ/rLX/6ib7/9VgkJCY62++Uvf6k+ffroySeflK+vr44dO6adO3fWqWYAVTAAoJZeffVVQ5Lx+eefV7tPfHy84ePjY6SkpDjWnTp1yggICDAGDhzoWBcbG2uMHj262vf54YcfDEnGH//4x1rXOXDgQCMgIMA4ceKE03q73e5Ynjp1qtGhQ4dKr120aJHx8/9ESjK8vLyM5ORkp/UfffSRIcnYsGGD0/pRo0YZnTp1cjz/73//a3h5eRn/+9//nPZ76aWXDEnGzp07DcMwjL/85S+GJOPMmTM1P1gAtUIXGIB6V1ZWpo8//ljx8fHq1KmTY314eLjuuOMO7dixQ3l5eZKk4OBgJScn6+jRo1W+V/PmzeXj46NPP/1UP/zwQ41rOHPmjLZv36677rpL7du3d9r2866t2rjpppvUs2dPp3WDBw9WmzZt9PbbbzvW/fDDD0pMTNSECRMc69555x316NFD3bt319mzZx2PwYMHS5K2bt0qqbxNJGn9+vWy2+11rhVA9QhAAOrdmTNndP78eXXr1q3Sth49eshut+vkyZOSpCeffFI5OTnq2rWrevfurQcffFAHDx507O/r66vnnntOH374oUJDQzVw4EAtW7ZMmZmZF63hu+++kyT16tWrHo9M6tixY6V1VqtVt956q9avX+8Yy/Puu++qtLTUKQAdPXpUycnJatu2rdOja9eukqSsrCxJ0oQJE3TDDTfonnvuUWhoqCZOnKg1a9YQhoB6RAAC4FYDBw5USkqKXnnlFfXq1Uv/+te/dM011+hf//qXY5+5c+fq22+/1dKlS+Xn56cnnnhCPXr00IEDBy7786s7G1RWVlbl+ubNm1e5fuLEicrPz9eHH34oSVqzZo26d++u2NhYxz52u129e/dWYmJilY9Zs2Y5PmP79u3avHmzfvOb3+jgwYOaMGGCbrnllmrrAlBL7u6DA9D4XGoMkM1mM/z9/Y3bb7+90rb77rvP8PLyMnJzc6t8bX5+vnH11VcbV1xxRbWf/+233xr+/v7G5MmTq90nKyvLkGQ88MADFz2W3/3ud0ZQUFCl9b/5zW+qHAM0e/bsKt+nrKzMCA8PNyZOnGicOXPGsFqtxqJFi5z2GTVqlHHFFVc4jUGqqWeeecaQZCQmJtb6tQAq4wwQgHrn7e2tYcOGaf369U6Xqp8+fVpvvPGGBgwYoMDAQElSdna202tbtmypzp07O7qSzp8/X+leO1deeaUCAgIqXTp+obZt22rgwIF65ZVXlJaW5rTNMAyn98rNzXXqdsvIyNC6detqdcxeXl769a9/rQ0bNui///2vbDabU/eXJN1+++36/vvv9c9//rPS63/88UcVFhZKks6dO1dp+1VXXSVJFz1mADVnMS78LwEA1MCqVas0ffp0zZw5UxEREZW2P/DAA0pLS1NcXJyCg4M1a9YsWa1W/eMf/9D333/vdBl8aGioBg0apL59+6p169bat2+fXn75Zc2ZM0cvvviikpKSNGTIEN1+++3q2bOnrFar1q1bp8TERK1du1a33nprtXV++eWXGjBggHx9fTVjxgx17NhRqamp+uCDD5SUlCSpPIB16NBBoaGh+u1vf6vz589r5cqVatu2rfbv3+8UliwWi2bPnq3ly5dX+Xk7d+7UgAEDFBAQoOjoaKdQJZV3gY0ZM0YffvihY5xPWVmZvvnmG61Zs0YfffSRrr32Ws2dO1fbt2/X6NGj1aFDB2VlZenvf/+7LBaLDh8+rKCgoNr+KwPwc+49AQWgMaroAqvucfLkScMwDGP//v3G8OHDjZYtWxr+/v7GzTffbOzatcvpvZ5++mmjX79+RnBwsNG8eXOje/fuxjPPPGOUlJQYhmEYZ8+eNWbPnm10797daNGihREUFGTExcUZa9asqVGthw8fNsaNG2cEBwcbfn5+Rrdu3YwnnnjCaZ+PP/7Y6NWrl+Hj42N069bNWL16dbWXwVfXBWYY5ZfXR0VFGZKMp59+usp9SkpKjOeee86IiYkxfH19jVatWhl9+/Y1lixZ4ugW3LJlizF27FgjIiLC8PHxMSIiIoxJkyYZ3377bY2OGcClcQYIAACYDmOAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6VjdXYAnstvtOnXqlAICAi5r1mgAAOA6hmEoPz9fERER8vK6+DkeAlAVTp06paioKHeXAQAA6uDkyZOKjIy86D4EoCoEBARIKm/AivmKAACAZ8vLy1NUVJTjd/xiCEBVqOj2CgwMJAABANDI1GT4CoOgAQCA6RCAAACA6RCAAACA6TAG6DKUlZWptLTU3WU0Os2aNZO3t7e7ywAAmBgBqA4Mw1BmZqZycnLcXUqjFRwcrLCwMO6zBABwCwJQHVSEn3bt2snf358f8VowDEPnz59XVlaWJCk8PNzNFQEAzIgAVEtlZWWO8BMSEuLuchql5s2bS5KysrLUrl07usMAAC7HIOhaqhjz4+/v7+ZKGreK9mMMFQDAHQhAdUS31+Wh/QAA7kQAAgAApkMAgqZNm6b4+Hh3lwEAgMswCBp64YUXZBiGu8sAAMBlCEAuZhiGSspK5OPt4zHjYIKCgtxdAgAALkUXmAsZhqHvcr/TsZxj+i73O5efdVm7dq169+6t5s2bKyQkREOHDlVhYWGlLrBBgwbpt7/9rR566CG1bt1aYWFhWrx4sdN75eTk6J577lHbtm0VGBiowYMH68svv3Tp8QAAUFcEIBcqKStRka1IklRkK1JJWYnLPjsjI0OTJk3SXXfdpa+//lqffvqpxo8fX20Ie+2119SiRQvt2bNHy5Yt05NPPqnExETH9ttuu01ZWVn68MMP9cUXX+iaa67RkCFDdO7cOVcdEgAAdUYXmAv5ePvIz+qnIluR/Kx+8pJV350pUPvW/rJ6N2wWzcjIkM1m0/jx49WhQwdJUu/evavdv0+fPlq0aJEkqUuXLlq+fLm2bNmiW265RTt27NDevXuVlZUlX19fSdKf/vQnJSQkaO3atZoxY0aDHgsAAJeLAORCFotFnYI6qaSsRF6y6taVu3Xw+1z1uSJI7866vkFDUGxsrIYMGaLevXtr+PDhGjZsmH7961+rVatWVe7fp08fp+fh4eGO6Su+/PJLFRQUVLoT9o8//qiUlJSGOQAAAOoRAcjFLBaLfK2++u5MgQ5+nytJOvh9rtLOnVenti0b7HO9vb2VmJioXbt26eOPP9bf/vY3PfbYY9qzZ0+V+zdr1qxS3Xa7XZJUUFCg8PBwffrpp5VeFxwcXN+lAwBQ7whAbmAYhkIDvdXniqDyM0CRQWrfuuGn1rBYLLrhhht0ww03aOHCherQoYPWrVtX6/e55pprlJmZKavVqujo6PovFACABkYAcrGKK8GKbEX60+Qwedti1SGkRYOPAdqzZ4+2bNmiYcOGqV27dtqzZ4/OnDmjHj166ODBg7V6r6FDh6p///6Kj4/XsmXL1LVrV506dUoffPCBxo0bp2uvvbaBjgIAgPrBVWAuduGVYKX2YkW29mnw8CNJgYGB2r59u0aNGqWuXbvq8ccf1/PPP6+RI0fW+r0sFos2btyogQMHavr06eratasmTpyoEydOKDQ0tAGqBwCgflkMbgFcSV5enoKCgpSbm6vAwECnbUVFRTp+/Lg6duwoPz+/Wr/3hWeA/Kx+6hTUyWNuiOhKl9uOAAD83MV+v3+OLjAXu/BKME+6GzQAAGZCAHKDiivBAACAezAGCAAAmA4BCAAAmA4BCAAAmA4ByI0Mw1Cxrdjls8IDAGB2DIJ2Ey6HBwDAfTgD5CYX3hCxyFakkrISN1cEAIB5EIDcxMfbR37W8hsA+ln95OPt4+aKAAAwDwKQm1TcELFzcOdG3/0VHR2tv/71r+4uAwCAGiMAuVHFDRFdFX4GDRqkuXPnuuSzAADwZAQgAABgOgQgk5g2bZq2bdumF154QRaLRRaLRSkpKbr77rvVsWNHNW/eXN26ddMLL7xQ6XXx8fH605/+pPDwcIWEhGj27NkqLS112u/8+fO66667FBAQoPbt2+vll1925eEBAFArBCCTeOGFF9S/f3/de++9ysjIUEZGhiIjIxUZGal33nlHX331lRYuXKhHH31Ua9ascXrt1q1blZKSoq1bt+q1117TqlWrtGrVKqd9nn/+eV177bU6cOCAZs2apZkzZ+rIkSMuPEIAAGqOAOROZTbp7LHyfzawoKAg+fj4yN/fX2FhYQoLC5Ovr6+WLFmia6+9Vh07dtTkyZM1ffr0SgGoVatWWr58ubp3765f/vKXGj16tLZs2eK0z6hRozRr1ix17txZDz/8sNq0aaOtW7c2+HEBAFAX3AjRXcps0r+HSqcOSBFXS3dvlrxd/69jxYoVeuWVV5SWlqYff/xRJSUluuqqq5z2iYmJkbe3t+N5eHi4Dh065LRPnz59HMsWi0VhYWHKyspq0NoBAKgrzgC5yw+p5eFHKv/nD6kuL+Gtt97S/Pnzdffdd+vjjz9WUlKSpk+frpIS55syNmvWzOm5xWKR3W6v9T4AAHgKtwag7du3a8yYMYqIiJDFYlFCQoLT9mnTpjkG7FY8RowYccn3XbFihaKjo+Xn56e4uDjt3bu3gY7gMrSKLj/zI8kefpWMVh0a/CN9fHxUVlbmeL5z505df/31mjVrlq6++mp17txZKSkpDV4HAADu5tYAVFhYqNjYWK1YsaLafUaMGOEYtJuRkaE333zzou/59ttva968eVq0aJH279+v2NhYDR8+3PO6Y7ytMu5OVNrUdfp63Iv6Lj+twSdFjY6O1p49e5SamqqzZ8+qS5cu2rdvnz766CN9++23euKJJ/T55583aA0AAHgCtwagkSNH6umnn9a4ceOq3cfX19cxaDcsLEytWrW66Hv++c9/1r333qvp06erZ8+eeumll+Tv769XXnmlvsu/bCWGXfkBoZKX1SXzgc2fP1/e3t7q2bOn2rZtq+HDh2v8+PGaMGGC4uLilJ2drVmzZjVoDQAAeAKL0dCnHWrIYrFo3bp1io+Pd6ybNm2aEhIS5OPjo1atWmnw4MF6+umnFRISUuV7lJSUyN/fX2vXrnV6n6lTpyonJ0fr16+v8nXFxcUqLi52PM/Ly1NUVJRyc3MVGBjotG9RUZGOHz+ujh07ys/Pr+4HLHPPCF+f7QgAgFT++x0UFFTl7/fPefQg6BEjRug///mPtmzZoueee07btm3TyJEjncaxXOjs2bMqKytTaGio0/rQ0FBlZmZW+zlLly5VUFCQ4xEVFVWvx1GdpjQfGAAAjYlHXwY/ceJEx3Lv3r3Vp08fXXnllfr00081ZMiQevucBQsWaN68eY7nFWeAXKFiPjAAAOA6Hn0G6Oc6deqkNm3a6NixY1Vub9Omjby9vXX69Gmn9adPn1ZYWFi17+vr66vAwECnBwAAaLoaVQBKT09Xdna2wsPDq9zu4+Ojvn37Ot2l2G63a8uWLerfv7+rygQAAB7OrQGooKBASUlJSkpKkiQdP35cSUlJSktLU0FBgR588EF99tlnSk1N1ZYtWzR27Fh17txZw4cPd7zHkCFDtHz5csfzefPm6Z///Kdee+01ff3115o5c6YKCws1ffp0Vx8eAADwUG4dA7Rv3z7dfPPNjucV43CmTp2qlStX6uDBg3rttdeUk5OjiIgIDRs2TE899ZR8fX8aM5OSkqKzZ886nk+YMEFnzpzRwoULlZmZqauuukqbNm2qNDAaAACYl8dcBu9JLnYZHZdv1w/aEQBQ35rMZfAAAAANgQAEAABMhwDkIQzDULGtuMHnA6utQYMGae7cue4uAwCAeuXRN0I0CzNPiQEAgDtwBsgDlJSVqMhWJEkumRTV8bklrvkcAAA8DQHIA/h4+8jPWn4llJ/VTz7ePg3yOYMGDdKcOXM0d+5ctWnTRsOHD9fhw4c1cuRItWzZUqGhofrNb37jdFuBn7NYLEpISHBaFxwcrFWrVjVIzQAANAQCkAdw5aSor732mnx8fLRz5049++yzGjx4sK6++mrt27dPmzZt0unTp3X77bc32OcDAOAJGAPkRja7Ten56YoMiJTVy+qSSVG7dOmiZcuWSZKefvppXX311frDH/7g2P7KK68oKipK3377rbp27drg9QAA4A4EIDex2W2asnGKkrOTFRMSo9WjVsvq1fD/Ovr27etY/vLLL7V161a1bNmy0n4pKSkEIABAk0UAcpP0/HQlZydLkpKzk5Wen67ooOgG/9wWLVo4lgsKCjRmzBg999xzlfarbsJZi8VS6VL90tLS+i0SAIAGRgByk8iASMWExDjOAEUGRLq8hmuuuUb/93//p+joaFmtNfsqtG3bVhkZGY7nR48e1fnz5xuqRAAAGgSDoN3E6mXV6lGrtSF+g8u6v35u9uzZOnfunCZNmqTPP/9cKSkp+uijjzR9+nSVlZVV+ZrBgwdr+fLlOnDggPbt26f77rtPzZo1c3HlAABcHgKQG1m9rIoOinZL+JGkiIgI7dy5U2VlZRo2bJh69+6tuXPnKjg4WF5eVX81nn/+eUVFRenGG2/UHXfcofnz58vf39/FlQMAcHmYDb4KzAbf8GhHAEB9YzZ4AACAiyAAAQAA0yEAeRBPnREeAICmhsvgPQQzwgMA4DqcAaqj+j5L464Z4d2Fs1wAAHciANVSxT1v6vvmf66aEd5TVLQf9xACALgDXWC15O3treDgYGVlZUmS/P39662rKsI3QqXWUjXzbqbi4uJ6eU9PYxiGzp8/r6ysLAUHB8vb29vdJQEATIgAVAdhYWGS5AhBqL3g4GBHOwIA4GoEoDqwWCwKDw9Xu3btmAi0Dpo1a8aZHwCAWxGALoO3tzc/5AAANEIMggYAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAPJANrtNqbmpstlt7i4FAIAmiTtBexib3aYpG6coOTtZMSExWj1qtaxe/GsCAKA+cQbIw6Tnpys5O1mSlJydrPT8dDdXBABA00MA8jCRAZGKCYmRJMWExCgyINLNFQEA0PTQt+JhrF5WrR61Wun56YoMiKT7CwCABsCvqweyelkVHRTt7jIAAGiy6AIDAACmQwACAACm49YAtH37do0ZM0YRERGyWCxKSEhwbCstLdXDDz+s3r17q0WLFoqIiNCdd96pU6dOXfQ9Fy9eLIvF4vTo3r17Ax8JAABoTNwagAoLCxUbG6sVK1ZU2nb+/Hnt379fTzzxhPbv3693331XR44c0a9+9atLvm9MTIwyMjIcjx07djRE+QAAoJFy6yDokSNHauTIkVVuCwoKUmJiotO65cuXq1+/fkpLS1P79u2rfV+r1aqwsLB6rRUAADQdjWoMUG5uriwWi4KDgy+639GjRxUREaFOnTpp8uTJSktLc02BAACgUWg0l8EXFRXp4Ycf1qRJkxQYGFjtfnFxcVq1apW6deumjIwMLVmyRDfeeKMOHz6sgICAKl9TXFys4uJix/O8vLx6rx8AAHiORhGASktLdfvtt8swDK1cufKi+17YpdanTx/FxcWpQ4cOWrNmje6+++4qX7N06VItWbKkXmsGAACey+O7wCrCz4kTJ5SYmHjRsz9VCQ4OVteuXXXs2LFq91mwYIFyc3Mdj5MnT15u2QAAwIN5dACqCD9Hjx7V5s2bFRISUuv3KCgoUEpKisLDw6vdx9fXV4GBgU4PAADQdLk1ABUUFCgpKUlJSUmSpOPHjyspKUlpaWkqLS3Vr3/9a+3bt0+vv/66ysrKlJmZqczMTJWUlDjeY8iQIVq+fLnj+fz587Vt2zalpqZq165dGjdunLy9vTVp0iRXH95lsdltSs1Nlc1uc3cpAAA0OW4dA7Rv3z7dfPPNjufz5s2TJE2dOlWLFy/We++9J0m66qqrnF63detWDRo0SJKUkpKis2fPOralp6dr0qRJys7OVtu2bTVgwAB99tlnatu2bcMeTD2y2W2asnGKkrOTFRMSo9WjVjMpKgAA9chiGIbh7iI8TV5enoKCgpSbm+uW7rDU3FSNSRjjeL4hfgOTowIAcAm1+f326DFAZhUZEKmYkBhJUkxIjCIDIt1cEQAATQv9Kh7I6mXV6lGrlZ6frsiASLq/AACoZ/yyeiirl5VuLwAAGghdYAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQB7OZrcpNTdVNrvN3aUAANBkMBeYB7PZbZqycYqSs5MVExKj1aNWMzEqAAD1gDNAHiw9P13J2cmSpOTsZKXnp7u5IgAAmgYCkAeLDIhUTEiMJCkmJEaRAZFurggAgKaB/hQPZvWyavWo1UrPT1dkQCTdXwAA1BN+UT2c1cuq6KBod5cBAECTQhcYAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQJQI2Cz25Samyqb3ebuUgAAaBKYC8zD2ew2Tdk4RcnZyYoJidHqUauZFBUAgMvEGSAPl56fruTsZElScnay0vPT3VwRAACNHwHIw0UGRComJEaSFBMSo8iASDdXBABA40dfioezelm1etRqpeenKzIgku4vAADqAb+mjYDVy6rooGh3lwEAQJNBFxgAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdtwag7du3a8yYMYqIiJDFYlFCQoLTdsMwtHDhQoWHh6t58+YaOnSojh49esn3XbFihaKjo+Xn56e4uDjt3bu3gY4AAAA0Rm4NQIWFhYqNjdWKFSuq3L5s2TK9+OKLeumll7Rnzx61aNFCw4cPV1FRUbXv+fbbb2vevHlatGiR9u/fr9jYWA0fPlxZWVkNdRgAAKCRsRiGYbi7CEmyWCxat26d4uPjJZWf/YmIiNDvf/97zZ8/X5KUm5ur0NBQrVq1ShMnTqzyfeLi4nTddddp+fLlkiS73a6oqCjdf//9euSRR2pUS15enoKCgpSbm6vAwMDLPzgAANDgavP77bFjgI4fP67MzEwNHTrUsS4oKEhxcXHavXt3la8pKSnRF1984fQaLy8vDR06tNrXAAAA8/HYO0FnZmZKkkJDQ53Wh4aGOrb93NmzZ1VWVlbla7755ptqP6u4uFjFxcWO53l5eXUtGwAANAIeewbIlZYuXaqgoCDHIyoqyt0lVclmtyk1N1U2u83dpQAA0Kh5bAAKCwuTJJ0+fdpp/enTpx3bfq5Nmzby9vau1WskacGCBcrNzXU8Tp48eZnV1z+b3aYpG6doTMIYTdk4hRAEAMBl8NgA1LFjR4WFhWnLli2OdXl5edqzZ4/69+9f5Wt8fHzUt29fp9fY7XZt2bKl2tdIkq+vrwIDA50eniY9P13J2cmSpOTsZKXnp7u5IgAAGi+3BqCCggIlJSUpKSlJUvnA56SkJKWlpclisWju3Ll6+umn9d577+nQoUO68847FRER4bhSTJKGDBniuOJLkubNm6d//vOfeu211/T1119r5syZKiws1PTp0118dPUrMiBSMSExkqSYkBhFBkS6uSIAABovtw6C3rdvn26++WbH83nz5kmSpk6dqlWrVumhhx5SYWGhZsyYoZycHA0YMECbNm2Sn5+f4zUpKSk6e/as4/mECRN05swZLVy4UJmZmbrqqqu0adOmSgOjGxurl1WrR61Wen66IgMiZfXy2PHrAAB4PI+5D5An4T5AAAA0Pk3iPkAAAAANhQAEAABMhwAEAABMhwAEAABMhwAEAABMhwAEAABMhwAEAABMhwAEAABMhwAEAABMhwDUyNjsNqXmpjIbPAAAl4EJpRoRm92mKRunKDk7WTEhMVo9ajVzggEAUAecAWpE0vPTlZydLElKzk5Wen66mysCAKBxIgA1IpEBkYoJiZEkxYTEKDIg0s0VAQDQONF/0ohYvaxaPWq10vPTFRkQSfcXAAB1xC9oI2P1sio6KNrdZQAA0KjRBQYAAEyHAAQAAEyHAAQAAEynTgHo5MmTSk//6RLsvXv3au7cuXr55ZfrrTAAAICGUqcAdMcdd2jr1q2SpMzMTN1yyy3au3evHnvsMT355JP1WiAAAEB9q1MAOnz4sPr16ydJWrNmjXr16qVdu3bp9ddf16pVq+qzPgAAgHpXpwBUWloqX19fSdLmzZv1q1/9SpLUvXt3ZWRk1F91AAAADaBOASgmJkYvvfSS/ve//ykxMVEjRoyQJJ06dUohISH1WiAAAEB9q1MAeu655/SPf/xDgwYN0qRJkxQbGytJeu+99xxdYwAAAJ7KYhiGUZcXlpWVKS8vT61atXKsS01Nlb+/v9q1a1dvBbpDXl6egoKClJubq8DAQHeXUyWb3caUGAAAXKA2v991OgP0448/qri42BF+Tpw4ob/+9a86cuRIow8/jYHNbtOUjVM0JmGMpmycIpvd5u6SAABoVOoUgMaOHav//Oc/kqScnBzFxcXp+eefV3x8vFauXFmvBaKy9Px0JWcnS5KSs5OVnp9+iVcAAIAL1SkA7d+/XzfeeKMkae3atQoNDdWJEyf0n//8Ry+++GK9FojKIgMiFRMSI0mKCYlRZECkmysCAKBxqdPgkfPnzysgIECS9PHHH2v8+PHy8vLSL37xC504caJeC0RlVi+rVo9azRggAADqqE5ngDp37qyEhASdPHlSH330kYYNGyZJysrK8thBw02N1cuq6KBowg8AAHVQpwC0cOFCzZ8/X9HR0erXr5/69+8vqfxs0NVXX12vBQIAANS3Ol8Gn5mZqYyMDMXGxsrLqzxH7d27V4GBgerevXu9FulqjeEyeAAA4Kw2v9917j8JCwtTWFiYY1b4yMhIboIIAAAahTp1gdntdj355JMKCgpShw4d1KFDBwUHB+upp56S3W6v7xoBAADqVZ3OAD322GP697//rWeffVY33HCDJGnHjh1avHixioqK9Mwzz9RrkQAAAPWpTmOAIiIi9NJLLzlmga+wfv16zZo1S99//329FegOjAECAKDxafCpMM6dO1flQOfu3bvr3LlzdXlLAAAAl6lTAIqNjdXy5csrrV++fLn69Olz2UUBAAA0pDqNAVq2bJlGjx6tzZs3O+4BtHv3bp08eVIbN26s1wIBAADqW53OAN1000369ttvNW7cOOXk5CgnJ0fjx49XcnKy/vvf/9Z3jaiGzW5Tam4qs8EDAFBLdb4RYlW+/PJLXXPNNSorK6uvt1R0dHSV84vNmjVLK1asqLR+1apVmj59utM6X19fFRUV1fgzG8MgaJvdpikbpyg5O1kxITFaPWo102IAAEzNJTdCdJXPP//cKVAdPnxYt9xyi2677bZqXxMYGKgjR444nlsslgat0R3S89OVnJ0sSUrOTlZ6frqig6LdWxQAAI2Exwegtm3bOj1/9tlndeWVV+qmm26q9jUWi0VhYWENXZpbRQZEKiYkxnEGKDIg0t0lAQDQaHh8ALpQSUmJVq9erXnz5l30rE5BQYE6dOggu92ua665Rn/4wx8UExPjwkobntXLqtWjVis9P12RAZF0fwEAUAu1+tUcP378Rbfn5ORcTi2XlJCQoJycHE2bNq3afbp166ZXXnlFffr0UW5urv70pz/p+uuvV3JysiIjqz5LUlxcrOLiYsfzvLy8+i69QVi9rHR7AQBQB7UaBP3zwcXVefXVV+tc0MUMHz5cPj4+2rBhQ41fU1paqh49emjSpEl66qmnqtxn8eLFWrJkSaX1njwIGgAAOKvNIOh6vQqsIZ04cUKdOnXSu+++q7Fjx9bqtbfddpusVqvefPPNKrdXdQYoKiqKAAQAQCPS4FNhuMOrr76qdu3aafTo0bV6XVlZmQ4dOqTw8PBq9/H19VVgYKDTAwAANF2NIgDZ7Xa9+uqrmjp1qqxW52FLd955pxYsWOB4/uSTT+rjjz/Wd999p/3792vKlCk6ceKE7rnnHleXDQAAPFSjuHRo8+bNSktL01133VVpW1pamry8fspxP/zwg+69915lZmaqVatW6tu3r3bt2qWePXu6smQAAODBGs0YIFdqDHeCBgAAzprkGCAAAID6QgBqApgUFQCA2mkUY4BQPSZFBQCg9jgD1MhVNSkqAAC4OAJQI1cxKaokJkUFAKCG6Ctp5JgUFQCA2uPXsglgUlQAAGqHLjAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BKAmgglRAQCoOW6E2AQwISoAALXDGaAmgAlRAQCoHQJQE8CEqAAA1A79JE0AE6ICAFA7/FI2EUyICgBAzdEFBgAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcA1MQwJxgAAJfGfYCaEOYEAwCgZjgD1IQwJxgAADVDAGpCmBMMAICaoX+kCWFOMAAAaoZfyCaGOcEAALg0usAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEICaIKbDAADg4rgMvolhOgwAAC6NM0BNDNNhAABwaR4dgBYvXiyLxeL06N69+0Vf884776h79+7y8/NT7969tXHjRhdV6xmYDgMAgEvz+L6RmJgYbd682fHcaq2+5F27dmnSpElaunSpfvnLX+qNN95QfHy89u/fr169ermiXLdjOgwAAC7No88ASeWBJywszPFo06ZNtfu+8MILGjFihB588EH16NFDTz31lK655hotX77chRW7X8V0GIQfAACq5vEB6OjRo4qIiFCnTp00efJkpaWlVbvv7t27NXToUKd1w4cP1+7duxu6TAAA0Ih49CmCuLg4rVq1St26dVNGRoaWLFmiG2+8UYcPH1ZAQECl/TMzMxUaGuq0LjQ0VJmZmRf9nOLiYhUXFzue5+Xl1c8BAAAAj+TRAWjkyJGO5T59+iguLk4dOnTQmjVrdPfdd9fb5yxdulRLliypt/cDAACezeO7wC4UHBysrl276tixY1VuDwsL0+nTp53WnT59WmFhYRd93wULFig3N9fxOHnyZL3VDAAAPE+jCkAFBQVKSUlReHh4ldv79++vLVu2OK1LTExU//79L/q+vr6+CgwMdHoAAICmy6MD0Pz587Vt2zalpqZq165dGjdunLy9vTVp0iRJ0p133qkFCxY49n/ggQe0adMmPf/88/rmm2+0ePFi7du3T3PmzHHXIbgVU2IAAFA1jx4DlJ6erkmTJik7O1tt27bVgAED9Nlnn6lt27aSpLS0NHl5/ZThrr/+er3xxht6/PHH9eijj6pLly5KSEgwzT2ALsSUGAAAVM9iGIbh7iI8TV5enoKCgpSbm9tou8NSc1M1JmGM4/mG+A2KDop2X0EAADSw2vx+e3QXGOqOKTEAAKgefSJNFFNiAABQPX4Vm7CKKTEAAIAzusAAAIDpEIAAAIDpEIAAAIDpEICaOG6GCABAZQyCbsK4GSIAAFXjDFATlp6fruTsZElScnay0vPT3VwRAACegQDUhHEzRAAAqkZ/SBPGzRABAKgav4hNHDdDBACgMrrAAACA6RCAAACA6RCAAACA6RCATIIbIgIA8BMGQZsAN0QEAMAZZ4BMgBsiAgDgjABkAtwQEQAAZ/SDmAA3RAQAwBm/hCbBDREBAPgJXWAAAMB0CEAAAMB0CEAmwr2AAAAoxxggk+BeQAAA/IQzQCbBvYAAAPgJAcgkuBcQAAA/oQ/EJLgXEAAAP+FX0ES4FxAAAOXoAgMAAKZDADIhLocHAJgdXWAmw+XwAABwBsh0uBweAAACkOlwOTwAAHSBmQ6XwwMAQAAyJS6HBwCYHV1gAADAdAhAJsWl8AAAM6MLzIS4FB4AYHacATIhLoUHAJgdAciEuBQeAGB2Hh2Ali5dquuuu04BAQFq166d4uPjdeTIkYu+ZtWqVbJYLE4PPz8/F1XcOFRcCr8hfgPdXwAAU/LoALRt2zbNnj1bn332mRITE1VaWqphw4apsLDwoq8LDAxURkaG43HixAkXVdx4XHgpPIOhAQBm49H/679p0yan56tWrVK7du30xRdfaODAgdW+zmKxKCwsrKHLa/QYDA0AMCuPPgP0c7m5uZKk1q1bX3S/goICdejQQVFRURo7dqySk5Mvun9xcbHy8vKcHmbAYGgAgFk1mgBkt9s1d+5c3XDDDerVq1e1+3Xr1k2vvPKK1q9fr9WrV8tut+v6669Xenr1P+5Lly5VUFCQ4xEVFdUQh+BxGAwNADAri2EYhruLqImZM2fqww8/1I4dOxQZWfMf6tLSUvXo0UOTJk3SU089VeU+xcXFKi4udjzPy8tTVFSUcnNzFRgYeNm1ezKb3ca8YACAJiEvL09BQUE1+v1uFL94c+bM0fvvv6/t27fXKvxIUrNmzXT11Vfr2LFj1e7j6+srX1/fyy2zUWJeMACAGXl0F5hhGJozZ47WrVunTz75RB07dqz1e5SVlenQoUMKDw9vgAqbBqbFAACYjUefAZo9e7beeOMNrV+/XgEBAcrMzJQkBQUFqXnz5pKkO++8U1dccYWWLl0qSXryySf1i1/8Qp07d1ZOTo7++Mc/6sSJE7rnnnvcdhyejCvBAABm5NG/dCtXrpQkDRo0yGn9q6++qmnTpkmS0tLS5OX104msH374Qffee68yMzPVqlUr9e3bV7t27VLPnj1dVXajUtWVYHSJAQCaukYzCNqVajOIqrHjDBAAoKlocoOg0XAqpsVIz09XWIswrggDAJgCv3KQ1cuqyIBIzgQBAEzDo68Cg+twV2gAgJkQgCCJu0IDAMyFPg5I+mks0IncE5LF3dUAANCwCEBw8tjOxxgHBABo8ugCgwPjgAAAZkEAgsOF44B6tu6pMqOM6TEAAE0SAQgOFeOAEn6VIFmk+PXxmrJxCiEIANDkEIDgxOpllbeXt77K/koSXWEAgKaJAIRKLuwK6xzcWWEtwtxcEQAA9YsAhEqsXlatGrFKXYK76FjOMU3bNI1uMABAk0IAQpUyCzN1NOeoJLrBAABNDwEIVeKKMABAU0YAcjFbmV3fnSmQrczu7lIuiivCAABNGQHIhWxldo3/+y4Nfn6bxv99V6MIQT+/IuxE7gk3VwUAwOUjALlQ2rnzOvh9riTp4Pe5Sjt33s0VXVpkQKR6tu7peP7ozkc5CwQAaPQIQC7UvrW/+lwRJEnqExmk9q393VzRpVm9rPrDjX9wPP8q+yvtydhDCAIANGoWwzAMdxfhafLy8hQUFKTc3FwFBgbW63vbyuxKO3de7Vv7y+rdOPKnzW7TlI1TlJydLD9vPxWVFalzcGe9OfpN+Vn93F0eAACSavf73Th+gZsQq7eX2rf2V9q58x4/BqhCxYDol4a+pKKyIknSsZxjuuODOzgTBABolAhALtbYBkJXsHpZFRcep87BnR3rjuYcpTsMANAoEYBcrDEOhK5g9bLqzdFvqktwF0mSn7ef7tt8n27bcJuKbEVurg4AgJojALlYYxwIfSE/q5/WjFlTqTts0vuT9O25b5WSk8IZIQCAx2MQdBUachC01DgHQv+czW7TbRtu07GcY5W29WjdQ0/f8LS8vbzVIbCDrF5WN1QIADCb2vx+E4Cq0NABqEJjD0JFtiLd8cEdjjnDqnJhGLqi5RXKLMxUZEAkoQgAUO8IQJepQQNQmU3KPiab3dDtb2coN/OourUL0Iuz4mXNTSvfp1W09ENq1cu56eX/9PaMAGGz23Qi94QW7Figr899fdF9L7yE/r8j/6vThacli3RFyyv0ff73l1zOLMxUWIuwGu3Lcv0u0/a0vVmWaW/XLTdEDwEB6DI1WAAqs0n/GiJlJEmSzhvN5G8plSTZvf3k9f/G1MjqJ9mqWG7WXCr9UWrXQ7p7s5Sf6TFhqCIIlRllenzn45cMQz5ePiqxl0iSfL18VWwvvuhyRXiqyb4s1+8ybU/bm2WZ9nbtcs+Qnnp91Ov1GoIIQJepwQLQ2WPS8r71814VwahdD+neT6VmnnNDwurC0IWhBwCADfEbFB0UXW/vx40QPVWraCn8KsdT44K7KF+4rGqXfX9arjgrlPW19M+by88ueQirl1VXtrpSXVt31Ruj31DCrxKUMDZB2yZsc1xC7+v107HUZNnP269Or2P58pdpe9reLMu0t2uXY0JiFBkQKXfhDFAVXDEGSJJsQe31278n6EhWvoLCumjNhDBZvbyqHwMUFCn9+xYp66vyMGQr/ul9J78rdbrJI7rDLsZmtyk9P71Ofez0zTMuwozLtD3t3VSXGQPkgVx1Fdh3Zwo0+PltjuevTb9ON3Ruc/Erwsps5YEoIOynMFQxNiji6vKxQR4eggAAaAh0gTUSF94UsXkzb0199XONfuF/Kiq5SHeWt1Vq01nybSn9f/8rP/NT+mP5tlMHfjpbBAAAqkUAciOrt5fenXW9Xpt+nX4sLZMkHckq0NgVO2s2R5i3tbzbK+Lq8ucRV5d3mQEAgIuir8TNrN5euqFzG3Vr11JHsgokSUdOF2jnsbOX7g6TykPQ3ZvLz/x4yCXxAAB4Os4AeQCrt5fWz7lB3UJbSqpFd1iFim4xwg8AADVCAPIQfj5WffDbGyt1h/1q+Q4dPZ1/6S6xMlv5fYY86HJ4AAA8FQHIg1zYHVbh26xC3fKX7Rc/G1Rmk/49tPwmi/8eSggCAOASCEAe5ufdYRUuOjj6h9TyK8AkrgQDAKAGCEAeqKI7LPF3A9X1grNBFYOjK4WgVtFcCQYAQC1wI8QquOpGiDVRVGLT2BU7deR0gZo389aPpWXq1q6l/m9mf2UVlKh9a//yK8UqbpAYFOlxM8YDAOAKTe5GiCtWrFB0dLT8/PwUFxenvXv3XnT/d955R927d5efn5969+6tjRs3uqjS+lfd4Oi+z2zR4Oe3afQL/1PBjyX67lyRbEHtpVdHMBYIAIBL8PgA9Pbbb2vevHlatGiR9u/fr9jYWA0fPlxZWVlV7r9r1y5NmjRJd999tw4cOKD4+HjFx8fr8OHDLq68/lQ1OLrYVt4NdmEYmvHXtU5jgYpPHVbq118o9esvVHS+wLFsKz4vZX1T/igt+mmZwAQAMAmP7wKLi4vTddddp+XLl0uS7Ha7oqKidP/99+uRRx6ptP+ECRNUWFio999/37HuF7/4ha666iq99NJLNfpMT+oCu9CF3WG+Vi9HCKrgrTKt81moPl7HJUnnjWbyt5RWWi6Sj/xUIkkyvP1kKSufWd4eGqu0gX+SvLwV1qGbMk8ckSSPWT7zfYraXnGlR9RitmXanrY3yzLt7brlyM69ZW3mo/rUZCZDLSkpkb+/v9auXav4+HjH+qlTpyonJ0fr16+v9Jr27dtr3rx5mjt3rmPdokWLlJCQoC+//LLKzykuLlZxcbHjeV5enqKiojwuAEmSrcyutHPn1a6lj259aXelMHSlJV1bfB+67M+pLjy5b9lH/pYSD6nFbMu0PW1vlmXa25XLR707q+Mju+s1BDWZMUBnz55VWVmZQkNDndaHhoYqMzOzytdkZmbWan9JWrp0qYKCghyPqKioyy++gVi9vdSpbUu1bO6jD357oz75/U364rEhjsvmM72v0Jf2TpLKv2gVarJ8oYovqOcsl3hQLWZbpu1pe7Ms096uXO5SdkwZqV/LXTw6ALnKggULlJub63icPHnS3SXVSJVhaOEI+c/8RKmTtsvr4VSlTvhEqRM+cSyn3LZFd7R6W0OKl2lI8TL9ouzfGlK8TLcUL9Uho6PjvWsbnhp+2ceDajHbMm1P25tlmfZ25fJR784Kj+4hd/Ho66TbtGkjb29vnT592mn96dOnFRYWVuVrwsLCarW/JPn6+srX1/fyC3ajijAkSV3CW0nhrSRJ0T36OvapWF7b3a7jZ/tJkqJaNdfJH34sXw66S6nHkyWV99OmXtBn6wnLJ/9f37wn1GK2ZdqetjfLMu3tuuWODTAGqDY8egyQVD4Iul+/fvrb3/4mqXwQdPv27TVnzpxqB0GfP39eGzZscKy7/vrr1adPn0Y/CBoAAFSvNr/fHn0GSJLmzZunqVOn6tprr1W/fv3017/+VYWFhZo+fbok6c4779QVV1yhpUuXSpIeeOAB3XTTTXr++ec1evRovfXWW9q3b59efvlldx4GAADwIB4fgCZMmKAzZ85o4cKFyszM1FVXXaVNmzY5BjqnpaXJy+unoUzXX3+93njjDT3++ON69NFH1aVLFyUkJKhXr17uOgQAAOBhPL4LzB3oAgMAoPFpMpfBAwAANAQCEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB2PnwrDHSpujp2Xl+fmSgAAQE1V/G7XZJILAlAV8vPzJUlRUVFurgQAANRWfn6+goKCLroPc4FVwW6369SpUwoICJDFYqnX987Ly1NUVJROnjzJPGOXQFvVHG1VO7RXzdFWtUN71VxDtJVhGMrPz1dERITTROlV4QxQFby8vBQZGdmgnxEYGMgfRw3RVjVHW9UO7VVztFXt0F41V99tdakzPxUYBA0AAEyHAAQAAEyHAORivr6+WrRokXx9fd1disejrWqOtqod2qvmaKvaob1qzt1txSBoAABgOpwBAgAApkMAAgAApkMAAgAApkMAAgAApkMAcqEVK1YoOjpafn5+iouL0969e91dktstXrxYFovF6dG9e3fH9qKiIs2ePVshISFq2bKlbr31Vp0+fdqNFbvW9u3bNWbMGEVERMhisSghIcFpu2EYWrhwocLDw9W8eXMNHTpUR48eddrn3Llzmjx5sgIDAxUcHKy7775bBQUFLjwK17hUW02bNq3Sd23EiBFO+5ilrZYuXarrrrtOAQEBateuneLj43XkyBGnfWryt5eWlqbRo0fL399f7dq104MPPiibzebKQ2lwNWmrQYMGVfpu3XfffU77mKGtJGnlypXq06eP4+aG/fv314cffujY7knfKwKQi7z99tuaN2+eFi1apP379ys2NlbDhw9XVlaWu0tzu5iYGGVkZDgeO3bscGz73e9+pw0bNuidd97Rtm3bdOrUKY0fP96N1bpWYWGhYmNjtWLFiiq3L1u2TC+++KJeeukl7dmzRy1atNDw4cNVVFTk2Gfy5MlKTk5WYmKi3n//fW3fvl0zZsxw1SG4zKXaSpJGjBjh9F178803nbabpa22bdum2bNn67PPPlNiYqJKS0s1bNgwFRYWOva51N9eWVmZRo8erZKSEu3atUuvvfaaVq1apYULF7rjkBpMTdpKku69916n79ayZcsc28zSVpIUGRmpZ599Vl988YX27dunwYMHa+zYsUpOTpbkYd8rAy7Rr18/Y/bs2Y7nZWVlRkREhLF06VI3VuV+ixYtMmJjY6vclpOTYzRr1sx45513HOu+/vprQ5Kxe/duF1XoOSQZ69atczy32+1GWFiY8cc//tGxLicnx/D19TXefPNNwzAM46uvvjIkGZ9//rljnw8//NCwWCzG999/77LaXe3nbWUYhjF16lRj7Nix1b7GrG1lGIaRlZVlSDK2bdtmGEbN/vY2btxoeHl5GZmZmY59Vq5caQQGBhrFxcWuPQAX+nlbGYZh3HTTTcYDDzxQ7WvM2lYVWrVqZfzrX//yuO8VZ4BcoKSkRF988YWGDh3qWOfl5aWhQ4dq9+7dbqzMMxw9elQRERHq1KmTJk+erLS0NEnSF198odLSUqd26969u9q3b0+7STp+/LgyMzOd2icoKEhxcXGO9tm9e7eCg4N17bXXOvYZOnSovLy8tGfPHpfX7G6ffvqp2rVrp27dumnmzJnKzs52bDNzW+Xm5kqSWrduLalmf3u7d+9W7969FRoa6thn+PDhysvLc/zfflP087aq8Prrr6tNmzbq1auXFixYoPPnzzu2mbWtysrK9NZbb6mwsFD9+/f3uO8Vk6G6wNmzZ1VWVub0L1SSQkND9c0337ipKs8QFxenVatWqVu3bsrIyNCSJUt044036vDhw8rMzJSPj4+Cg4OdXhMaGqrMzEz3FOxBKtqgqu9VxbbMzEy1a9fOabvValXr1q1N14YjRozQ+PHj1bFjR6WkpOjRRx/VyJEjtXv3bnl7e5u2rex2u+bOnasbbrhBvXr1kqQa/e1lZmZW+d2r2NYUVdVWknTHHXeoQ4cOioiI0MGDB/Xwww/ryJEjevfddyWZr60OHTqk/v37q6ioSC1bttS6devUs2dPJSUledT3igAEtxo5cqRjuU+fPoqLi1OHDh20Zs0aNW/e3I2VoamZOHGiY7l3797q06ePrrzySn366acaMmSIGytzr9mzZ+vw4cNOY+9Qtera6sJxYr1791Z4eLiGDBmilJQUXXnlla4u0+26deumpKQk5ebmau3atZo6daq2bdvm7rIqoQvMBdq0aSNvb+9KI91Pnz6tsLAwN1XlmYKDg9W1a1cdO3ZMYWFhKikpUU5OjtM+tFu5ija42PcqLCys0kB7m82mc+fOmb4NO3XqpDZt2ujYsWOSzNlWc+bM0fvvv6+tW7cqMjLSsb4mf3thYWFVfvcqtjU11bVVVeLi4iTJ6btlprby8fFR586d1bdvXy1dulSxsbF64YUXPO57RQByAR8fH/Xt21dbtmxxrLPb7dqyZYv69+/vxso8T0FBgVJSUhQeHq6+ffuqWbNmTu125MgRpaWl0W6SOnbsqLCwMKf2ycvL0549exzt079/f+Xk5OiLL75w7PPJJ5/Ibrc7/iNtVunp6crOzlZ4eLgkc7WVYRiaM2eO1q1bp08++UQdO3Z02l6Tv73+/fvr0KFDTqExMTFRgYGB6tmzp2sOxAUu1VZVSUpKkiSn75YZ2qo6drtdxcXFnve9qtch1ajWW2+9Zfj6+hqrVq0yvvrqK2PGjBlGcHCw00h3M/r9739vfPrpp8bx48eNnTt3GkOHDjXatGljZGVlGYZhGPfdd5/Rvn1745NPPjH27dtn9O/f3+jfv7+bq3ad/Px848CBA8aBAwcMScaf//xn48CBA8aJEycMwzCMZ5991ggODjbWr19vHDx40Bg7dqzRsWNH48cff3S8x4gRI4yrr77a2LNnj7Fjxw6jS5cuxqRJk9x1SA3mYm2Vn59vzJ8/39i9e7dx/PhxY/PmzcY111xjdOnSxSgqKnK8h1naaubMmUZQUJDx6aefGhkZGY7H+fPnHftc6m/PZrMZvXr1MoYNG2YkJSUZmzZtMtq2bWssWLDAHYfUYC7VVseOHTOefPJJY9++fcbx48eN9evXG506dTIGDhzoeA+ztJVhGMYjjzxibNu2zTh+/Lhx8OBB45FHHjEsFovx8ccfG4bhWd8rApAL/e1vfzPat29v+Pj4GP369TM+++wzd5fkdhMmTDDCw8MNHx8f44orrjAmTJhgHDt2zLH9xx9/NGbNmmW0atXK8Pf3N8aNG2dkZGS4sWLX2rp1qyGp0mPq1KmGYZRfCv/EE08YoaGhhq+vrzFkyBDjyJEjTu+RnZ1tTJo0yWjZsqURGBhoTJ8+3cjPz3fD0TSsi7XV+fPnjWHDhhlt27Y1mjVrZnTo0MG49957K/0PiFnaqqp2kmS8+uqrjn1q8reXmppqjBw50mjevLnRpk0b4/e//71RWlrq4qNpWJdqq7S0NGPgwIFG69atDV9fX6Nz587Ggw8+aOTm5jq9jxnayjAM46677jI6dOhg+Pj4GG3btjWGDBniCD+G4VnfK4thGEb9nlMCAADwbIwBAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAoAasFgsSkhIcHcZAOoJAQiAx5s2bZosFkulx4gRI9xdGoBGyuruAgCgJkaMGKFXX33VaZ2vr6+bqgHQ2HEGCECj4Ovrq7CwMKdHq1atJJV3T61cuVIjR45U8+bN1alTJ61du9bp9YcOHdLgwYPVvHlzhYSEaMaMGSooKHDa55VXXlFMTIx8fX0VHh6uOXPmOG0/e/asxo0bJ39/f3Xp0kXvvfdewx40gAZDAALQJDzxxBO69dZb9eWXX2ry5MmaOHGivv76a0lSYWGhhg8frlatWunzzz/XO++8o82bNzsFnJUrV2r27NmaMWOGDh06pPfee0+dO3d2+owlS5bo9ttv18GDBzVq1ChNnjxZ586dc+lxAqgn9T69KgDUs6lTpxre3t5GixYtnB7PPPOMYRjlM3bfd999Tq+Ji4szZs6caRiGYbz88stGq1atjIKCAsf2Dz74wPDy8nLMCB8REWE89thj1dYgyXj88ccdzwsKCgxJxocfflhvxwnAdRgDBKBRuPnmm7Vy5Uqnda1bt3Ys9+/f32lb//79lZSUJEn6+uuvFRsbqxYtWji233DDDbLb7Tpy5IgsFotOnTqlIUOGXLSGPn36OJZbtGihwMBAZWVl1fWQALgRAQhAo9CiRYtKXVL1pXnz5jXar1mzZk7PLRaL7HZ7Q5QEoIExBghAk/DZZ59Vet6jRw9JUo8ePfTll1+qsLDQsX3nzp3y8vJSt27dFBAQoOjoaG3ZssWlNQNwH84AAWgUiouLlZmZ6bTOarWqTZs2kqR33nlH1157rQYMGKDXX39de/fu1b///W9J0uTJk7Vo0SJNnTpVixcv1pkzZ3T//ffrN7/5jUJDQyVJixcv1n333ad27dpp5MiRys/P186dO3X//fe79kABuAQBCECjsGnTJoWHhzut69atm7755htJ5VdovfXWW5o1a5bCw8P15ptvqmfPnpIkf39/ffTRR3rggQd03XXXyd/fX7feeqv+/Oc/O95r6tSpKioq0l/+8hfNnz9fbdq00a9//WvXHSAAl7IYhmG4uwgAuBwWi0Xr1q1TfHy8u0sB0EgwBggAAJgOAQgAAJgOY4AANHr05AOoLc4AAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0/n/ATR+URpdtQFNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "crgFcY-HZyxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot solutions to the ODE learnt from each model\n",
        "\n",
        "times, sine_model_outputs = evaluate(model, t)\n",
        "times, tanh_model_outputs = evaluate(tanh_model, t)\n",
        "times, relu_model_outputs = evaluate(relu_model, t)\n",
        "\n",
        "plt.scatter(times, tanh_model_outputs, label = 'tanh', s = 2)\n",
        "plt.scatter(times, sine_model_outputs, label = 'sine', s = 2)\n",
        "plt.scatter(times, relu_model_outputs, label = 'relu', s = 2)\n",
        "plt.scatter(times, solution_to_ODE(times), label = 'true', s = 2)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Solutions')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S6IBEjPvxKmt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "beaa8e1e-4c8c-42fc-dbe9-578d4f80e405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}